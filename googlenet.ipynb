{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6913dfec-8a94-4068-ba41-4b9d40f5c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732028380.894146  222897 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.1899 - loss: 2.4657 - val_accuracy: 0.2308 - val_loss: 1.8785 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.3161 - loss: 1.7789 - val_accuracy: 0.2308 - val_loss: 2.0960 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.3986 - loss: 1.5615 - val_accuracy: 0.2692 - val_loss: 2.0760 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.3865 - loss: 1.5838 - val_accuracy: 0.3077 - val_loss: 2.1332 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4593 - loss: 1.4208 - val_accuracy: 0.3077 - val_loss: 1.8632 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4862 - loss: 1.3990 - val_accuracy: 0.3846 - val_loss: 1.6411 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4431 - loss: 1.3668 - val_accuracy: 0.4231 - val_loss: 1.4631 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.3603 - loss: 1.4081 - val_accuracy: 0.3846 - val_loss: 1.3577 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5039 - loss: 1.2339 - val_accuracy: 0.4615 - val_loss: 1.3008 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4463 - loss: 1.3472 - val_accuracy: 0.4615 - val_loss: 1.2520 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4314 - loss: 1.5106 - val_accuracy: 0.5000 - val_loss: 1.2075 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4671 - loss: 1.3972 - val_accuracy: 0.5000 - val_loss: 1.2100 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5369 - loss: 1.2632 - val_accuracy: 0.4615 - val_loss: 1.2348 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5607 - loss: 1.2669 - val_accuracy: 0.5000 - val_loss: 1.2155 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4932 - loss: 1.2696 - val_accuracy: 0.5000 - val_loss: 1.1918 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5074 - loss: 1.2120 - val_accuracy: 0.4615 - val_loss: 1.1806 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5786 - loss: 1.1181 - val_accuracy: 0.5000 - val_loss: 1.1570 - learning_rate: 2.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5313 - loss: 1.2204 - val_accuracy: 0.4615 - val_loss: 1.1234 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4996 - loss: 1.2732 - val_accuracy: 0.5000 - val_loss: 1.0968 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5017 - loss: 1.2301 - val_accuracy: 0.5385 - val_loss: 1.0834 - learning_rate: 2.5000e-04\n",
      "Epoch 1/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.4822 - loss: 1.3123 - val_accuracy: 0.5769 - val_loss: 1.0647 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4492 - loss: 1.4090 - val_accuracy: 0.5769 - val_loss: 1.0549 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5232 - loss: 1.1533 - val_accuracy: 0.5769 - val_loss: 1.0534 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5505 - loss: 1.2466 - val_accuracy: 0.5769 - val_loss: 1.0526 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5148 - loss: 1.2282 - val_accuracy: 0.5769 - val_loss: 1.0529 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5006 - loss: 1.2268 - val_accuracy: 0.5385 - val_loss: 1.0522 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4696 - loss: 1.2499 - val_accuracy: 0.5385 - val_loss: 1.0526 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5565 - loss: 1.0890 - val_accuracy: 0.5385 - val_loss: 1.0524 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.5704 - loss: 1.1242 - val_accuracy: 0.5385 - val_loss: 1.0540 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4828 - loss: 1.2096 - val_accuracy: 0.5385 - val_loss: 1.0554 - learning_rate: 5.0000e-06\n",
      "Epoch 11/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4s/step - accuracy: 0.4737 - loss: 1.3924 - val_accuracy: 0.5769 - val_loss: 1.0570 - learning_rate: 5.0000e-06\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5667 - loss: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9404824376106262\n",
      "Test Accuracy: 0.5666666626930237\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to your dataset\n",
    "dataset_path = '/home/batch25/Desktop/initial data'\n",
    "train_path = '/home/batch25/Desktop/train_data2'\n",
    "val_path = '/home/batch25/Desktop/val_data2'\n",
    "test_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Function to split dataset into train, validation, and test sets\n",
    "def split_dataset(dataset_path, train_path, val_path, test_path, train_split=0.8, val_split=0.1, test_split=0.1):\n",
    "    if os.path.exists(train_path): shutil.rmtree(train_path)\n",
    "    if os.path.exists(val_path): shutil.rmtree(val_path)\n",
    "    if os.path.exists(test_path): shutil.rmtree(test_path)\n",
    "\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(val_path, exist_ok=True)\n",
    "    os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    for class_folder in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = os.listdir(class_path)\n",
    "            images = [os.path.join(class_path, img) for img in images]\n",
    "            train, temp = train_test_split(images, test_size=(1 - train_split))\n",
    "            val, test = train_test_split(temp, test_size=test_split / (val_split + test_split))\n",
    "\n",
    "            # Create class subdirectories\n",
    "            os.makedirs(os.path.join(train_path, class_folder), exist_ok=True)\n",
    "            os.makedirs(os.path.join(val_path, class_folder), exist_ok=True)\n",
    "            os.makedirs(os.path.join(test_path, class_folder), exist_ok=True)\n",
    "\n",
    "            # Move files\n",
    "            for img in train:\n",
    "                shutil.copy(img, os.path.join(train_path, class_folder))\n",
    "            for img in val:\n",
    "                shutil.copy(img, os.path.join(val_path, class_folder))\n",
    "            for img in test:\n",
    "                shutil.copy(img, os.path.join(test_path, class_folder))\n",
    "\n",
    "# Split the dataset\n",
    "split_dataset(dataset_path, train_path, val_path, test_path)\n",
    "\n",
    "# Load the InceptionV3 base model (GoogLeNet), excluding the top fully connected layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the base model initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the custom model\n",
    "model = Sequential([\n",
    "    base_model,                      # Pre-trained InceptionV3 base model\n",
    "    GlobalAveragePooling2D(),        # Global average pooling to flatten features\n",
    "    Dense(256, activation='relu'),   # Dense layer with 256 units\n",
    "    BatchNormalization(),            # Batch normalization for stability\n",
    "    Dropout(0.5),                    # Dropout to prevent overfitting\n",
    "    Dense(128, activation='relu'),   # Dense layer with 128 units\n",
    "    Dropout(0.3),                    # Dropout for regularization\n",
    "    Dense(5, activation='softmax')   # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Callbacks for early stopping and reducing learning rate\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Train the model with frozen layers\n",
    "initial_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"googlenet_hasta_recognition_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e2cd1d-6896-4294-8ea8-277f04417a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 5 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      1.00      0.80         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          12       0.50      0.67      0.57         6\n",
      "          20       0.67      0.67      0.67         6\n",
      "           5       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.49      0.57      0.52        30\n",
      "weighted avg       0.49      0.57      0.52        30\n",
      "\n",
      "Test Accuracy: 0.5667\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize ImageDataGenerator for the test set (rescale the pixel values)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the test dataset\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    '/home/batch25/Desktop/test_data2',  # Path to your test data\n",
    "    target_size=(128, 128),              # Ensure this matches your model input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False                        # Do not shuffle to keep predictions aligned with true labels\n",
    ")\n",
    "\n",
    "# Get true labels from the test data generator\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class indices\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate a classification report\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee8bd54-62f3-4846-a789-73269213dbe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,906,085</span> (91.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,906,085\u001b[0m (91.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,301</span> (8.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,103,301\u001b[0m (8.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,802,784\u001b[0m (83.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.2182 - loss: 9.7895 - val_accuracy: 0.2308 - val_loss: 4.8356\n",
      "Epoch 2/50\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4062 - loss: 5.8180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 592ms/step - accuracy: 0.4062 - loss: 5.8180 - val_accuracy: 0.2692 - val_loss: 6.2313\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.4068 - loss: 4.7569 - val_accuracy: 0.3846 - val_loss: 2.7427\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 573ms/step - accuracy: 0.3438 - loss: 3.6984 - val_accuracy: 0.3846 - val_loss: 2.3137\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.4293 - loss: 1.7752 - val_accuracy: 0.3846 - val_loss: 1.7935\n",
      "Epoch 6/50\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.2692 - loss: 1.8007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:29:27.647091: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 586ms/step - accuracy: 0.2692 - loss: 1.8007 - val_accuracy: 0.3846 - val_loss: 1.6833\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.4662 - loss: 1.2357 - val_accuracy: 0.4615 - val_loss: 1.3345\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600ms/step - accuracy: 0.4688 - loss: 1.1646 - val_accuracy: 0.4615 - val_loss: 1.3205\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.4738 - loss: 1.1968 - val_accuracy: 0.4615 - val_loss: 1.2404\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 576ms/step - accuracy: 0.5625 - loss: 0.9074 - val_accuracy: 0.5000 - val_loss: 1.2279\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.5422 - loss: 1.0470 - val_accuracy: 0.4231 - val_loss: 1.2398\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 583ms/step - accuracy: 0.7188 - loss: 0.8731 - val_accuracy: 0.5000 - val_loss: 1.2320\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6515 - loss: 0.9504 - val_accuracy: 0.4615 - val_loss: 1.2367\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593ms/step - accuracy: 0.5625 - loss: 1.0933 - val_accuracy: 0.5000 - val_loss: 1.2586\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.6576 - loss: 0.8845 - val_accuracy: 0.5000 - val_loss: 1.1966\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 584ms/step - accuracy: 0.6875 - loss: 0.9684 - val_accuracy: 0.5000 - val_loss: 1.1904\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.7154 - loss: 0.8174 - val_accuracy: 0.4615 - val_loss: 1.1591\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584ms/step - accuracy: 0.6250 - loss: 0.9437 - val_accuracy: 0.5000 - val_loss: 1.1856\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.7057 - loss: 0.7678 - val_accuracy: 0.5769 - val_loss: 1.2376\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585ms/step - accuracy: 0.6250 - loss: 0.9140 - val_accuracy: 0.5000 - val_loss: 1.2999\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.6441 - loss: 0.8731 - val_accuracy: 0.5000 - val_loss: 1.1664\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 583ms/step - accuracy: 0.7188 - loss: 0.8271 - val_accuracy: 0.5769 - val_loss: 1.2061\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6354 - loss: 0.8391 - val_accuracy: 0.5385 - val_loss: 1.2634\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 584ms/step - accuracy: 0.6875 - loss: 0.9729 - val_accuracy: 0.5769 - val_loss: 1.2113\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6793 - loss: 0.8022 - val_accuracy: 0.5000 - val_loss: 1.0701\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 590ms/step - accuracy: 0.7500 - loss: 0.6301 - val_accuracy: 0.5769 - val_loss: 1.0755\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.6468 - loss: 0.7681 - val_accuracy: 0.5385 - val_loss: 1.0356\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 591ms/step - accuracy: 0.7500 - loss: 0.7105 - val_accuracy: 0.5385 - val_loss: 1.0661\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7167 - loss: 0.7330 - val_accuracy: 0.5000 - val_loss: 1.0317\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 595ms/step - accuracy: 0.6250 - loss: 1.0298 - val_accuracy: 0.4615 - val_loss: 1.0260\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6944 - loss: 0.7970 - val_accuracy: 0.5385 - val_loss: 1.0695\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 590ms/step - accuracy: 0.6562 - loss: 0.7658 - val_accuracy: 0.5385 - val_loss: 1.0131\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.7710 - loss: 0.7132 - val_accuracy: 0.5769 - val_loss: 1.0248\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597ms/step - accuracy: 0.8438 - loss: 0.5146 - val_accuracy: 0.5769 - val_loss: 1.0719\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6547 - loss: 0.7967 - val_accuracy: 0.6154 - val_loss: 0.9717\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599ms/step - accuracy: 0.7188 - loss: 0.8571 - val_accuracy: 0.5769 - val_loss: 0.9594\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7244 - loss: 0.6996 - val_accuracy: 0.6154 - val_loss: 0.8568\n",
      "Epoch 38/50\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 623ms/step - accuracy: 0.7500 - loss: 0.6627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:36:41.167040: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597ms/step - accuracy: 0.7500 - loss: 0.6627 - val_accuracy: 0.6154 - val_loss: 0.8394\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6897 - loss: 0.8131 - val_accuracy: 0.5385 - val_loss: 0.8369\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 577ms/step - accuracy: 0.6250 - loss: 0.8273 - val_accuracy: 0.5000 - val_loss: 0.9123\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6321 - loss: 0.8825 - val_accuracy: 0.6154 - val_loss: 0.9408\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 594ms/step - accuracy: 0.7188 - loss: 0.6656 - val_accuracy: 0.6154 - val_loss: 0.9161\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7205 - loss: 0.7442 - val_accuracy: 0.5769 - val_loss: 0.9571\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 588ms/step - accuracy: 0.7500 - loss: 0.6095 - val_accuracy: 0.6154 - val_loss: 0.9502\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7368 - loss: 0.6854 - val_accuracy: 0.5385 - val_loss: 1.0028\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 609ms/step - accuracy: 0.8125 - loss: 0.5114 - val_accuracy: 0.5385 - val_loss: 1.0090\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7236 - loss: 0.6780 - val_accuracy: 0.6154 - val_loss: 1.0707\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 603ms/step - accuracy: 0.5938 - loss: 0.9111 - val_accuracy: 0.6154 - val_loss: 0.9941\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7098 - loss: 0.6609 - val_accuracy: 0.5385 - val_loss: 1.0211\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 603ms/step - accuracy: 0.8125 - loss: 0.5002 - val_accuracy: 0.5385 - val_loss: 1.0952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5333 - loss: 1.0074\n",
      "Test Accuracy: 0.5333333611488342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67         6\n",
      "          10       0.50      0.67      0.57         6\n",
      "          12       0.50      0.17      0.25         6\n",
      "          20       0.50      0.83      0.62         6\n",
      "           5       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.53      0.53      0.50        30\n",
      "weighted avg       0.53      0.53      0.50        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Paths to your datasets (update these paths accordingly)\n",
    "train_data_path = '/home/batch25/Desktop/train_data2'\n",
    "val_data_path = '/home/batch25/Desktop/val_data2'\n",
    "test_data_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')  # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Print classification metrics\n",
    "print(classification_report(true_labels, test_predictions, target_names=test_generator.class_indices.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b94fd39-2d39-400d-bbaf-d65a4d11a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:27:19.298750: W tensorflow/core/framework/op_kernel.cc:1829] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n",
      "         [0.66371846, 0.67940474, 0.67548317],\n",
      "         [0.6645063 , 0.6801926 , 0.676271  ],\n",
      "         ...,\n",
      "         [0.68771964, 0.6955628 , 0.6837981 ],\n",
      "         [0.6921863 , 0.70002943, 0.6882647 ],\n",
      "         [0.7087425 , 0.7131948 , 0.7065163 ]],\n",
      "\n",
      "        [[0.6696548 , 0.68895155, 0.6741987 ],\n",
      "         [0.66199183, 0.6787342 , 0.6716444 ],\n",
      "         [0.66182005, 0.6775063 , 0.67358476],\n",
      "         ...,\n",
      "         [0.6883113 , 0.6961544 , 0.6843897 ],\n",
      "         [0.7061592 , 0.7119031 , 0.7032871 ],\n",
      "         [0.7135745 , 0.7144795 , 0.713122  ]],\n",
      "\n",
      "        [[0.6482417 , 0.6582724 , 0.6457785 ],\n",
      "         [0.666122  , 0.68381566, 0.66876745],\n",
      "         [0.66483945, 0.68253094, 0.6725936 ],\n",
      "         ...,\n",
      "         [0.7035758 , 0.7106114 , 0.700058  ],\n",
      "         [0.7168738 , 0.7172604 , 0.71668047],\n",
      "         [0.68946654, 0.69572884, 0.6863353 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4241208 , 0.39666983, 0.36648002],\n",
      "         [0.42744532, 0.39999434, 0.37645352],\n",
      "         [0.44072625, 0.41327527, 0.38310826],\n",
      "         ...,\n",
      "         [0.61628085, 0.6297491 , 0.62582755],\n",
      "         [0.6109359 , 0.6266222 , 0.62270063],\n",
      "         [0.5964689 , 0.6121552 , 0.60823363]],\n",
      "\n",
      "        [[0.42679948, 0.3993485 , 0.374516  ],\n",
      "         [0.4381429 , 0.41069192, 0.38181657],\n",
      "         [0.43068182, 0.40945858, 0.37601012],\n",
      "         ...,\n",
      "         [0.6071522 , 0.61499536, 0.6110738 ],\n",
      "         [0.6134333 , 0.62500316, 0.6210816 ],\n",
      "         [0.6166311 , 0.63231736, 0.6283958 ]],\n",
      "\n",
      "        [[0.43555957, 0.40810856, 0.38052487],\n",
      "         [0.43455684, 0.4113961 , 0.37859347],\n",
      "         [0.4212739 , 0.4055876 , 0.3702935 ],\n",
      "         ...,\n",
      "         [0.605832  , 0.6136751 , 0.60975355],\n",
      "         [0.606203  , 0.61404616, 0.6101246 ],\n",
      "         [0.6105857 , 0.6202572 , 0.61633563]]],\n",
      "\n",
      "\n",
      "       [[[0.6702271 , 0.674239  , 0.65463114],\n",
      "         [0.6569136 , 0.66425383, 0.644646  ],\n",
      "         [0.66620386, 0.67122155, 0.6516137 ],\n",
      "         ...,\n",
      "         [0.6096904 , 0.61753356, 0.6039216 ],\n",
      "         [0.61347497, 0.6213181 , 0.6039216 ],\n",
      "         [0.6180461 , 0.62588924, 0.6094278 ]],\n",
      "\n",
      "        [[0.6612392 , 0.6670306 , 0.64742273],\n",
      "         [0.66475403, 0.6701342 , 0.65052634],\n",
      "         [0.6583634 , 0.66534114, 0.6457333 ],\n",
      "         ...,\n",
      "         [0.6170946 , 0.6249377 , 0.6072075 ],\n",
      "         [0.6227714 , 0.6306145 , 0.62045336],\n",
      "         [0.6257891 , 0.63363224, 0.62904596]],\n",
      "\n",
      "        [[0.6514386 , 0.6591901 , 0.6395823 ],\n",
      "         [0.66808045, 0.6725036 , 0.65289575],\n",
      "         [0.659281  , 0.66602945, 0.6464216 ],\n",
      "         ...,\n",
      "         [0.6273751 , 0.63521826, 0.63126636],\n",
      "         [0.6179138 , 0.6257569 , 0.6180205 ],\n",
      "         [0.60845244, 0.6162956 , 0.60477453]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.55871516, 0.5482166 , 0.5347226 ],\n",
      "         [0.54357696, 0.5387552 , 0.523369  ],\n",
      "         [0.5475453 , 0.54362375, 0.5279375 ],\n",
      "         ...,\n",
      "         [0.5857413 , 0.58680785, 0.5714824 ],\n",
      "         [0.57100755, 0.56922644, 0.56102395],\n",
      "         [0.5568628 , 0.54901963, 0.5529412 ]],\n",
      "\n",
      "        [[0.5462765 , 0.54235494, 0.52666867],\n",
      "         [0.5538456 , 0.549924  , 0.53423774],\n",
      "         [0.5477589 , 0.5438373 , 0.52815104],\n",
      "         ...,\n",
      "         [0.5877014 , 0.5848477 , 0.5754027 ],\n",
      "         [0.584373  , 0.5881761 , 0.568746  ],\n",
      "         [0.5614298 , 0.555544  , 0.55555093]],\n",
      "\n",
      "        [[0.5502965 , 0.5463749 , 0.53068864],\n",
      "         [0.53515834, 0.53123677, 0.5155505 ],\n",
      "         [0.52754146, 0.52225244, 0.5058824 ],\n",
      "         ...,\n",
      "         [0.5768261 , 0.57433075, 0.5664876 ],\n",
      "         [0.58633316, 0.586216  , 0.57266617],\n",
      "         [0.57515067, 0.5751451 , 0.56339145]]],\n",
      "\n",
      "\n",
      "       [[[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        [[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        [[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2627451 , 0.24313727, 0.227451  ],\n",
      "         [0.2624982 , 0.24289036, 0.22720408],\n",
      "         [0.25764015, 0.23803233, 0.22234605],\n",
      "         ...,\n",
      "         [0.606281  , 0.61411256, 0.6071493 ],\n",
      "         [0.5752385 , 0.5752385 , 0.5673954 ],\n",
      "         [0.5886889 , 0.5886889 , 0.58098215]],\n",
      "\n",
      "        [[0.2454188 , 0.22581096, 0.21012469],\n",
      "         [0.24056077, 0.22095291, 0.20526664],\n",
      "         [0.22809128, 0.20965442, 0.19338267],\n",
      "         ...,\n",
      "         [0.5930967 , 0.5966677 , 0.5941863 ],\n",
      "         [0.5775832 , 0.577598  , 0.57565373],\n",
      "         [0.5693904 , 0.5693904 , 0.5679485 ]],\n",
      "\n",
      "        [[0.1893903 , 0.17502724, 0.15671857],\n",
      "         [0.17400652, 0.16126281, 0.14214447],\n",
      "         [0.16054372, 0.1510202 , 0.13269301],\n",
      "         ...,\n",
      "         [0.57923335, 0.57923335, 0.5741497 ],\n",
      "         [0.5798973 , 0.5798973 , 0.57897556],\n",
      "         [0.5688231 , 0.5688231 , 0.561959  ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.64720964, 0.6390931 , 0.61717576],\n",
      "         [0.6291522 , 0.60873026, 0.5667028 ],\n",
      "         [0.54421103, 0.50418735, 0.446914  ],\n",
      "         ...,\n",
      "         [0.6616009 , 0.6616009 , 0.669444  ],\n",
      "         [0.6379089 , 0.6379089 , 0.645752  ],\n",
      "         [0.6442394 , 0.6420949 , 0.65637153]],\n",
      "\n",
      "        [[0.604105  , 0.604105  , 0.61194813],\n",
      "         [0.6358349 , 0.6298511 , 0.6157539 ],\n",
      "         [0.6568783 , 0.6428547 , 0.60580367],\n",
      "         ...,\n",
      "         [0.64469045, 0.64469045, 0.6525336 ],\n",
      "         [0.63915324, 0.6378564 , 0.6495899 ],\n",
      "         [0.65355515, 0.6499703 , 0.668568  ]],\n",
      "\n",
      "        [[0.6069939 , 0.6069939 , 0.61483705],\n",
      "         [0.60481596, 0.60481596, 0.6126591 ],\n",
      "         [0.62446004, 0.6206091 , 0.614332  ],\n",
      "         ...,\n",
      "         [0.63406706, 0.63361794, 0.6428084 ],\n",
      "         [0.65183604, 0.6484255 , 0.6665004 ],\n",
      "         [0.64509994, 0.64362884, 0.65588516]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6468055 , 0.6507271 , 0.65857023],\n",
      "         [0.63495946, 0.638881  , 0.64672416],\n",
      "         [0.6334374 , 0.63735896, 0.6452021 ],\n",
      "         ...,\n",
      "         [0.6115359 , 0.61534315, 0.6231863 ],\n",
      "         [0.60718   , 0.60880923, 0.61665237],\n",
      "         [0.6061168 , 0.6061168 , 0.6139599 ]],\n",
      "\n",
      "        [[0.63835025, 0.6422718 , 0.65011495],\n",
      "         [0.6325897 , 0.63651127, 0.6443544 ],\n",
      "         [0.63606524, 0.6399868 , 0.64782995],\n",
      "         ...,\n",
      "         [0.6200883 , 0.62400985, 0.631853  ],\n",
      "         [0.61355436, 0.6174759 , 0.62531906],\n",
      "         [0.60860187, 0.61094195, 0.6187851 ]],\n",
      "\n",
      "        [[0.63174194, 0.6356635 , 0.64350665],\n",
      "         [0.6347035 , 0.6386251 , 0.6464682 ],\n",
      "         [0.64240664, 0.6463282 , 0.65417135],\n",
      "         ...,\n",
      "         [0.6165621 , 0.6204837 , 0.62832683],\n",
      "         [0.622221  , 0.62614256, 0.63398576],\n",
      "         [0.6156871 , 0.61960864, 0.6274518 ]]],\n",
      "\n",
      "\n",
      "       [[[0.64773804, 0.6937124 , 0.7023661 ],\n",
      "         [0.6805998 , 0.7113957 , 0.70936567],\n",
      "         [0.6923581 , 0.708786  , 0.69526166],\n",
      "         ...,\n",
      "         [0.5351249 , 0.53904647, 0.55865437],\n",
      "         [0.5265592 , 0.53048074, 0.5500886 ],\n",
      "         [0.5094734 , 0.51339495, 0.5330028 ]],\n",
      "\n",
      "        [[0.6354102 , 0.6921714 , 0.70390713],\n",
      "         [0.662108  , 0.7006088 , 0.7047427 ],\n",
      "         [0.69659096, 0.7207238 , 0.71336347],\n",
      "         ...,\n",
      "         [0.50631404, 0.5102356 , 0.52984345],\n",
      "         [0.49027678, 0.49419835, 0.51380616],\n",
      "         [0.49170056, 0.49562213, 0.51523   ]],\n",
      "\n",
      "        [[0.6230823 , 0.69063044, 0.7054481 ],\n",
      "         [0.64607096, 0.693504  , 0.70257455],\n",
      "         [0.67809916, 0.7099369 , 0.70874053],\n",
      "         ...,\n",
      "         [0.49196386, 0.49588543, 0.5154933 ],\n",
      "         [0.49338767, 0.49730924, 0.51691705],\n",
      "         [0.5017496 , 0.50567114, 0.525279  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.44557983, 0.42989355, 0.39459944],\n",
      "         [0.45309615, 0.43740988, 0.40211576],\n",
      "         [0.4540029 , 0.4365034 , 0.4018137 ],\n",
      "         ...,\n",
      "         [0.5916848 , 0.5917206 , 0.622986  ],\n",
      "         [0.5972675 , 0.5990413 , 0.6250924 ],\n",
      "         [0.612251  , 0.6160147 , 0.63609606]],\n",
      "\n",
      "        [[0.45575145, 0.44006518, 0.40477106],\n",
      "         [0.4693951 , 0.45370883, 0.4184147 ],\n",
      "         [0.45354035, 0.43785408, 0.40255997],\n",
      "         ...,\n",
      "         [0.59961164, 0.5996894 , 0.6308287 ],\n",
      "         [0.61776626, 0.6193479 , 0.643849  ],\n",
      "         [0.6070473 , 0.6086046 , 0.6317589 ]],\n",
      "\n",
      "        [[0.45285028, 0.437164  , 0.4018699 ],\n",
      "         [0.4740296 , 0.45834333, 0.4230492 ],\n",
      "         [0.47326672, 0.45758045, 0.42228633],\n",
      "         ...,\n",
      "         [0.61106807, 0.6102909 , 0.63977414],\n",
      "         [0.6275784 , 0.62379116, 0.65506595],\n",
      "         [0.59622025, 0.5938252 , 0.6246469 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5546962 , 0.5546962 , 0.54685307],\n",
      "         [0.54813915, 0.54813915, 0.540296  ],\n",
      "         [0.54861397, 0.54861397, 0.54077077],\n",
      "         ...,\n",
      "         [0.64410377, 0.6519469 , 0.64269924],\n",
      "         [0.6592606 , 0.6671037 , 0.655339  ],\n",
      "         [0.673348  , 0.68119115, 0.66942644]],\n",
      "\n",
      "        [[0.56272256, 0.56272256, 0.5548794 ],\n",
      "         [0.5561655 , 0.5561655 , 0.5483224 ],\n",
      "         [0.5496086 , 0.5496086 , 0.54176545],\n",
      "         ...,\n",
      "         [0.6402757 , 0.64811885, 0.63635415],\n",
      "         [0.6780858 , 0.68592894, 0.67416424],\n",
      "         [0.66821384, 0.676057  , 0.6642923 ]],\n",
      "\n",
      "        [[0.5686275 , 0.5693346 , 0.55937004],\n",
      "         [0.56419194, 0.56419194, 0.5563488 ],\n",
      "         [0.55763495, 0.55763495, 0.5497918 ],\n",
      "         ...,\n",
      "         [0.6591009 , 0.6669441 , 0.6551793 ],\n",
      "         [0.6733915 , 0.68123466, 0.66946995],\n",
      "         [0.6666667 , 0.6745098 , 0.6627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.52435905, 0.5206889 , 0.5048769 ],\n",
      "         [0.5306105 , 0.5237435 , 0.5078924 ],\n",
      "         [0.5557164 , 0.5450898 , 0.5316385 ],\n",
      "         ...,\n",
      "         [0.6       , 0.6179292 , 0.6072789 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ]],\n",
      "\n",
      "        [[0.52230513, 0.51838356, 0.5022947 ],\n",
      "         [0.5105155 , 0.50659394, 0.48706782],\n",
      "         [0.55385613, 0.5493634 , 0.531265  ],\n",
      "         ...,\n",
      "         [0.5982698 , 0.61438864, 0.6091694 ],\n",
      "         [0.6       , 0.6174394 , 0.6082585 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ]],\n",
      "\n",
      "        [[0.5236826 , 0.519761  , 0.5019608 ],\n",
      "         [0.52711487, 0.5231933 , 0.5035854 ],\n",
      "         [0.54622304, 0.5423015 , 0.52308977],\n",
      "         ...,\n",
      "         [0.587568  , 0.6063623 , 0.5931167 ],\n",
      "         [0.5963106 , 0.6129193 , 0.6062307 ],\n",
      "         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.]], dtype=float32)).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n",
      "    return nest_util.flatten_up_to(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n",
      "    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n",
      "    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n",
      "         [0.66371846, 0.67940474, 0.67548317],\n",
      "         [0.6645063 , 0.6801926 , 0.676271  ],\n",
      "         ...,\n",
      "         [0.68771964, 0.6955628 , 0.6837981 ],\n",
      "         [0.6921863 , 0.70002943, 0.6882647 ],\n",
      "         [0.7087425 , 0.7131948 , 0.7065163 ]],\n",
      "\n",
      "        [[0.6696548 , 0.68895155, 0.6741987 ],\n",
      "         [0.66199183, 0.6787342 , 0.6716444 ],\n",
      "         [0.66182005, 0.6775063 , 0.67358476],\n",
      "         ...,\n",
      "         [0.6883113 , 0.6961544 , 0.6843897 ],\n",
      "         [0.7061592 , 0.7119031 , 0.7032871 ],\n",
      "         [0.7135745 , 0.7144795 , 0.713122  ]],\n",
      "\n",
      "        [[0.6482417 , 0.6582724 , 0.6457785 ],\n",
      "         [0.666122  , 0.68381566, 0.66876745],\n",
      "         [0.66483945, 0.68253094, 0.6725936 ],\n",
      "         ...,\n",
      "         [0.7035758 , 0.7106114 , 0.700058  ],\n",
      "         [0.7168738 , 0.7172604 , 0.71668047],\n",
      "         [0.68946654, 0.69572884, 0.6863353 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4241208 , 0.39666983, 0.36648002],\n",
      "         [0.42744532, 0.39999434, 0.37645352],\n",
      "         [0.44072625, 0.41327527, 0.38310826],\n",
      "         ...,\n",
      "         [0.61628085, 0.6297491 , 0.62582755],\n",
      "         [0.6109359 , 0.6266222 , 0.62270063],\n",
      "         [0.5964689 , 0.6121552 , 0.60823363]],\n",
      "\n",
      "        [[0.42679948, 0.3993485 , 0.374516  ],\n",
      "         [0.4381429 , 0.41069192, 0.38181657],\n",
      "         [0.43068182, 0.40945858, 0.37601012],\n",
      "         ...,\n",
      "         [0.6071522 , 0.61499536, 0.6110738 ],\n",
      "         [0.6134333 , 0.62500316, 0.6210816 ],\n",
      "         [0.6166311 , 0.63231736, 0.6283958 ]],\n",
      "\n",
      "        [[0.43555957, 0.40810856, 0.38052487],\n",
      "         [0.43455684, 0.4113961 , 0.37859347],\n",
      "         [0.4212739 , 0.4055876 , 0.3702935 ],\n",
      "         ...,\n",
      "         [0.605832  , 0.6136751 , 0.60975355],\n",
      "         [0.606203  , 0.61404616, 0.6101246 ],\n",
      "         [0.6105857 , 0.6202572 , 0.61633563]]],\n",
      "\n",
      "\n",
      "       [[[0.6702271 , 0.674239  , 0.65463114],\n",
      "         [0.6569136 , 0.66425383, 0.644646  ],\n",
      "         [0.66620386, 0.67122155, 0.6516137 ],\n",
      "         ...,\n",
      "         [0.6096904 , 0.61753356, 0.6039216 ],\n",
      "         [0.61347497, 0.6213181 , 0.6039216 ],\n",
      "         [0.6180461 , 0.62588924, 0.6094278 ]],\n",
      "\n",
      "        [[0.6612392 , 0.6670306 , 0.64742273],\n",
      "         [0.66475403, 0.6701342 , 0.65052634],\n",
      "         [0.6583634 , 0.66534114, 0.6457333 ],\n",
      "         ...,\n",
      "         [0.6170946 , 0.6249377 , 0.6072075 ],\n",
      "         [0.6227714 , 0.6306145 , 0.62045336],\n",
      "         [0.6257891 , 0.63363224, 0.62904596]],\n",
      "\n",
      "        [[0.6514386 , 0.6591901 , 0.6395823 ],\n",
      "         [0.66808045, 0.6725036 , 0.65289575],\n",
      "         [0.659281  , 0.66602945, 0.6464216 ],\n",
      "         ...,\n",
      "         [0.6273751 , 0.63521826, 0.63126636],\n",
      "         [0.6179138 , 0.6257569 , 0.6180205 ],\n",
      "         [0.60845244, 0.6162956 , 0.60477453]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.55871516, 0.5482166 , 0.5347226 ],\n",
      "         [0.54357696, 0.5387552 , 0.523369  ],\n",
      "         [0.5475453 , 0.54362375, 0.5279375 ],\n",
      "      "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n         [0.66371846, 0.67940474, 0.67548317],\n         [0.6645063 , 0.6801926 , 0.676271  ],\n         ...,\n         [0.68771964, 0.6955628 , 0.6837981 ],\n         [0.6921863 , 0.70002943, 0.6882647 ],\n         [0.7087425 , 0.7131948 , 0.7065163 ]],\n\n        [[0.6696548 , 0.68895155, 0.6741987 ],\n         [0.66199183, 0.6787342 , 0.6716444 ],\n         [0.66182005, 0.6775063 , 0.67358476],\n         ...,\n         [0.6883113 , 0.6961544 , 0.6843897 ],\n         [0.7061592 , 0.7119031 , 0.7032871 ],\n         [0.7135745 , 0.7144795 , 0.713122  ]],\n\n        [[0.6482417 , 0.6582724 , 0.6457785 ],\n         [0.666122  , 0.68381566, 0.66876745],\n         [0.66483945, 0.68253094, 0.6725936 ],\n         ...,\n         [0.7035758 , 0.7106114 , 0.700058  ],\n         [0.7168738 , 0.7172604 , 0.71668047],\n         [0.68946654, 0.69572884, 0.6863353 ]],\n\n        ...,\n\n        [[0.4241208 , 0.39666983, 0.36648002],\n         [0.42744532, 0.39999434, 0.37645352],\n         [0.44072625, 0.41327527, 0.38310826],\n         ...,\n         [0.61628085, 0.6297491 , 0.62582755],\n         [0.6109359 , 0.6266222 , 0.62270063],\n         [0.5964689 , 0.6121552 , 0.60823363]],\n\n        [[0.42679948, 0.3993485 , 0.374516  ],\n         [0.4381429 , 0.41069192, 0.38181657],\n         [0.43068182, 0.40945858, 0.37601012],\n         ...,\n         [0.6071522 , 0.61499536, 0.6110738 ],\n         [0.6134333 , 0.62500316, 0.6210816 ],\n         [0.6166311 , 0.63231736, 0.6283958 ]],\n\n        [[0.43555957, 0.40810856, 0.38052487],\n         [0.43455684, 0.4113961 , 0.37859347],\n         [0.4212739 , 0.4055876 , 0.3702935 ],\n         ...,\n         [0.605832  , 0.6136751 , 0.60975355],\n         [0.606203  , 0.61404616, 0.6101246 ],\n         [0.6105857 , 0.6202572 , 0.61633563]]],\n\n\n       [[[0.6702271 , 0.674239  , 0.65463114],\n         [0.6569136 , 0.66425383, 0.644646  ],\n         [0.66620386, 0.67122155, 0.6516137 ],\n         ...,\n         [0.6096904 , 0.61753356, 0.6039216 ],\n         [0.61347497, 0.6213181 , 0.6039216 ],\n         [0.6180461 , 0.62588924, 0.6094278 ]],\n\n        [[0.6612392 , 0.6670306 , 0.64742273],\n         [0.66475403, 0.6701342 , 0.65052634],\n         [0.6583634 , 0.66534114, 0.6457333 ],\n         ...,\n         [0.6170946 , 0.6249377 , 0.6072075 ],\n         [0.6227714 , 0.6306145 , 0.62045336],\n         [0.6257891 , 0.63363224, 0.62904596]],\n\n        [[0.6514386 , 0.6591901 , 0.6395823 ],\n         [0.66808045, 0.6725036 , 0.65289575],\n         [0.659281  , 0.66602945, 0.6464216 ],\n         ...,\n         [0.6273751 , 0.63521826, 0.63126636],\n         [0.6179138 , 0.6257569 , 0.6180205 ],\n         [0.60845244, 0.6162956 , 0.60477453]],\n\n        ...,\n\n        [[0.55871516, 0.5482166 , 0.5347226 ],\n         [0.54357696, 0.5387552 , 0.523369  ],\n         [0.5475453 , 0.54362375, 0.5279375 ],\n         ...,\n         [0.5857413 , 0.58680785, 0.5714824 ],\n         [0.57100755, 0.56922644, 0.56102395],\n         [0.5568628 , 0.54901963, 0.5529412 ]],\n\n        [[0.5462765 , 0.54235494, 0.52666867],\n         [0.5538456 , 0.549924  , 0.53423774],\n         [0.5477589 , 0.5438373 , 0.52815104],\n         ...,\n         [0.5877014 , 0.5848477 , 0.5754027 ],\n         [0.584373  , 0.5881761 , 0.568746  ],\n         [0.5614298 , 0.555544  , 0.55555093]],\n\n        [[0.5502965 , 0.5463749 , 0.53068864],\n         [0.53515834, 0.53123677, 0.5155505 ],\n         [0.52754146, 0.52225244, 0.5058824 ],\n         ...,\n         [0.5768261 , 0.57433075, 0.5664876 ],\n         [0.58633316, 0.586216  , 0.57266617],\n         [0.57515067, 0.5751451 , 0.56339145]]],\n\n\n       [[[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        ...,\n\n        [[0.2627451 , 0.24313727, 0.227451  ],\n         [0.2624982 , 0.24289036, 0.22720408],\n         [0.25764015, 0.23803233, 0.22234605],\n         ...,\n         [0.606281  , 0.61411256, 0.6071493 ],\n         [0.5752385 , 0.5752385 , 0.5673954 ],\n         [0.5886889 , 0.5886889 , 0.58098215]],\n\n        [[0.2454188 , 0.22581096, 0.21012469],\n         [0.24056077, 0.22095291, 0.20526664],\n         [0.22809128, 0.20965442, 0.19338267],\n         ...,\n         [0.5930967 , 0.5966677 , 0.5941863 ],\n         [0.5775832 , 0.577598  , 0.57565373],\n         [0.5693904 , 0.5693904 , 0.5679485 ]],\n\n        [[0.1893903 , 0.17502724, 0.15671857],\n         [0.17400652, 0.16126281, 0.14214447],\n         [0.16054372, 0.1510202 , 0.13269301],\n         ...,\n         [0.57923335, 0.57923335, 0.5741497 ],\n         [0.5798973 , 0.5798973 , 0.57897556],\n         [0.5688231 , 0.5688231 , 0.561959  ]]],\n\n\n       ...,\n\n\n       [[[0.64720964, 0.6390931 , 0.61717576],\n         [0.6291522 , 0.60873026, 0.5667028 ],\n         [0.54421103, 0.50418735, 0.446914  ],\n         ...,\n         [0.6616009 , 0.6616009 , 0.669444  ],\n         [0.6379089 , 0.6379089 , 0.645752  ],\n         [0.6442394 , 0.6420949 , 0.65637153]],\n\n        [[0.604105  , 0.604105  , 0.61194813],\n         [0.6358349 , 0.6298511 , 0.6157539 ],\n         [0.6568783 , 0.6428547 , 0.60580367],\n         ...,\n         [0.64469045, 0.64469045, 0.6525336 ],\n         [0.63915324, 0.6378564 , 0.6495899 ],\n         [0.65355515, 0.6499703 , 0.668568  ]],\n\n        [[0.6069939 , 0.6069939 , 0.61483705],\n         [0.60481596, 0.60481596, 0.6126591 ],\n         [0.62446004, 0.6206091 , 0.614332  ],\n         ...,\n         [0.63406706, 0.63361794, 0.6428084 ],\n         [0.65183604, 0.6484255 , 0.6665004 ],\n         [0.64509994, 0.64362884, 0.65588516]],\n\n        ...,\n\n        [[0.6468055 , 0.6507271 , 0.65857023],\n         [0.63495946, 0.638881  , 0.64672416],\n         [0.6334374 , 0.63735896, 0.6452021 ],\n         ...,\n         [0.6115359 , 0.61534315, 0.6231863 ],\n         [0.60718   , 0.60880923, 0.61665237],\n         [0.6061168 , 0.6061168 , 0.6139599 ]],\n\n        [[0.63835025, 0.6422718 , 0.65011495],\n         [0.6325897 , 0.63651127, 0.6443544 ],\n         [0.63606524, 0.6399868 , 0.64782995],\n         ...,\n         [0.6200883 , 0.62400985, 0.631853  ],\n         [0.61355436, 0.6174759 , 0.62531906],\n         [0.60860187, 0.61094195, 0.6187851 ]],\n\n        [[0.63174194, 0.6356635 , 0.64350665],\n         [0.6347035 , 0.6386251 , 0.6464682 ],\n         [0.64240664, 0.6463282 , 0.65417135],\n         ...,\n         [0.6165621 , 0.6204837 , 0.62832683],\n         [0.622221  , 0.62614256, 0.63398576],\n         [0.6156871 , 0.61960864, 0.6274518 ]]],\n\n\n       [[[0.64773804, 0.6937124 , 0.7023661 ],\n         [0.6805998 , 0.7113957 , 0.70936567],\n         [0.6923581 , 0.708786  , 0.69526166],\n         ...,\n         [0.5351249 , 0.53904647, 0.55865437],\n         [0.5265592 , 0.53048074, 0.5500886 ],\n         [0.5094734 , 0.51339495, 0.5330028 ]],\n\n        [[0.6354102 , 0.6921714 , 0.70390713],\n         [0.662108  , 0.7006088 , 0.7047427 ],\n         [0.69659096, 0.7207238 , 0.71336347],\n         ...,\n         [0.50631404, 0.5102356 , 0.52984345],\n         [0.49027678, 0.49419835, 0.51380616],\n         [0.49170056, 0.49562213, 0.51523   ]],\n\n        [[0.6230823 , 0.69063044, 0.7054481 ],\n         [0.64607096, 0.693504  , 0.70257455],\n         [0.67809916, 0.7099369 , 0.70874053],\n         ...,\n         [0.49196386, 0.49588543, 0.5154933 ],\n         [0.49338767, 0.49730924, 0.51691705],\n         [0.5017496 , 0.50567114, 0.525279  ]],\n\n        ...,\n\n        [[0.44557983, 0.42989355, 0.39459944],\n         [0.45309615, 0.43740988, 0.40211576],\n         [0.4540029 , 0.4365034 , 0.4018137 ],\n         ...,\n         [0.5916848 , 0.5917206 , 0.622986  ],\n         [0.5972675 , 0.5990413 , 0.6250924 ],\n         [0.612251  , 0.6160147 , 0.63609606]],\n\n        [[0.45575145, 0.44006518, 0.40477106],\n         [0.4693951 , 0.45370883, 0.4184147 ],\n         [0.45354035, 0.43785408, 0.40255997],\n         ...,\n         [0.59961164, 0.5996894 , 0.6308287 ],\n         [0.61776626, 0.6193479 , 0.643849  ],\n         [0.6070473 , 0.6086046 , 0.6317589 ]],\n\n        [[0.45285028, 0.437164  , 0.4018699 ],\n         [0.4740296 , 0.45834333, 0.4230492 ],\n         [0.47326672, 0.45758045, 0.42228633],\n         ...,\n         [0.61106807, 0.6102909 , 0.63977414],\n         [0.6275784 , 0.62379116, 0.65506595],\n         [0.59622025, 0.5938252 , 0.6246469 ]]],\n\n\n       [[[0.5546962 , 0.5546962 , 0.54685307],\n         [0.54813915, 0.54813915, 0.540296  ],\n         [0.54861397, 0.54861397, 0.54077077],\n         ...,\n         [0.64410377, 0.6519469 , 0.64269924],\n         [0.6592606 , 0.6671037 , 0.655339  ],\n         [0.673348  , 0.68119115, 0.66942644]],\n\n        [[0.56272256, 0.56272256, 0.5548794 ],\n         [0.5561655 , 0.5561655 , 0.5483224 ],\n         [0.5496086 , 0.5496086 , 0.54176545],\n         ...,\n         [0.6402757 , 0.64811885, 0.63635415],\n         [0.6780858 , 0.68592894, 0.67416424],\n         [0.66821384, 0.676057  , 0.6642923 ]],\n\n        [[0.5686275 , 0.5693346 , 0.55937004],\n         [0.56419194, 0.56419194, 0.5563488 ],\n         [0.55763495, 0.55763495, 0.5497918 ],\n         ...,\n         [0.6591009 , 0.6669441 , 0.6551793 ],\n         [0.6733915 , 0.68123466, 0.66946995],\n         [0.6666667 , 0.6745098 , 0.6627451 ]],\n\n        ...,\n\n        [[0.52435905, 0.5206889 , 0.5048769 ],\n         [0.5306105 , 0.5237435 , 0.5078924 ],\n         [0.5557164 , 0.5450898 , 0.5316385 ],\n         ...,\n         [0.6       , 0.6179292 , 0.6072789 ],\n         [0.6       , 0.61960787, 0.6039216 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.52230513, 0.51838356, 0.5022947 ],\n         [0.5105155 , 0.50659394, 0.48706782],\n         [0.55385613, 0.5493634 , 0.531265  ],\n         ...,\n         [0.5982698 , 0.61438864, 0.6091694 ],\n         [0.6       , 0.6174394 , 0.6082585 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.5236826 , 0.519761  , 0.5019608 ],\n         [0.52711487, 0.5231933 , 0.5035854 ],\n         [0.54622304, 0.5423015 , 0.52308977],\n         ...,\n         [0.587568  , 0.6063623 , 0.5931167 ],\n         [0.5963106 , 0.6129193 , 0.6062307 ],\n         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0.]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n         [0.66371846, 0.67940474, 0.67548317],\n         [0.6645063 , 0.6801926 , 0.676271  ],\n         ...,\n         [0.68771964, 0.6955628 , 0.6837981 ],\n         [0.6921863 , 0.70002943, 0.6882647 ],\n         [0.7087425 , 0.7131948 , 0.7065163 ]],\n\n        [[0.6696548 , 0.68895155, 0.6741987 ],\n         [0.66199183, 0.6787342 , 0.6716444 ],\n         [0.66182005, 0.6775063 , 0.67358476],\n         ...,\n         [0.6883113 , 0.6961544 , 0.6843897 ],\n         [0.7061592 , 0.7119031 , 0.7032871 ],\n         [0.7135745 , 0.7144795 , 0.713122  ]],\n\n        [[0.6482417 , 0.6582724 , 0.6457785 ],\n         [0.666122  , 0.68381566, 0.66876745],\n         [0.66483945, 0.68253094, 0.6725936 ],\n         ...,\n         [0.7035758 , 0.7106114 , 0.700058  ],\n         [0.7168738 , 0.7172604 , 0.71668047],\n         [0.68946654, 0.69572884, 0.6863353 ]],\n\n        ...,\n\n        [[0.4241208 , 0.39666983, 0.36648002],\n         [0.42744532, 0.39999434, 0.37645352],\n         [0.44072625, 0.41327527, 0.38310826],\n         ...,\n         [0.61628085, 0.6297491 , 0.62582755],\n         [0.6109359 , 0.6266222 , 0.62270063],\n         [0.5964689 , 0.6121552 , 0.60823363]],\n\n        [[0.42679948, 0.3993485 , 0.374516  ],\n         [0.4381429 , 0.41069192, 0.38181657],\n         [0.43068182, 0.40945858, 0.37601012],\n         ...,\n         [0.6071522 , 0.61499536, 0.6110738 ],\n         [0.6134333 , 0.62500316, 0.6210816 ],\n         [0.6166311 , 0.63231736, 0.6283958 ]],\n\n        [[0.43555957, 0.40810856, 0.38052487],\n         [0.43455684, 0.4113961 , 0.37859347],\n         [0.4212739 , 0.4055876 , 0.3702935 ],\n         ...,\n         [0.605832  , 0.6136751 , 0.60975355],\n         [0.606203  , 0.61404616, 0.6101246 ],\n         [0.6105857 , 0.6202572 , 0.61633563]]],\n\n\n       [[[0.6702271 , 0.674239  , 0.65463114],\n         [0.6569136 , 0.66425383, 0.644646  ],\n         [0.66620386, 0.67122155, 0.6516137 ],\n         ...,\n         [0.6096904 , 0.61753356, 0.6039216 ],\n         [0.61347497, 0.6213181 , 0.6039216 ],\n         [0.6180461 , 0.62588924, 0.6094278 ]],\n\n        [[0.6612392 , 0.6670306 , 0.64742273],\n         [0.66475403, 0.6701342 , 0.65052634],\n         [0.6583634 , 0.66534114, 0.6457333 ],\n         ...,\n         [0.6170946 , 0.6249377 , 0.6072075 ],\n         [0.6227714 , 0.6306145 , 0.62045336],\n         [0.6257891 , 0.63363224, 0.62904596]],\n\n        [[0.6514386 , 0.6591901 , 0.6395823 ],\n         [0.66808045, 0.6725036 , 0.65289575],\n         [0.659281  , 0.66602945, 0.6464216 ],\n         ...,\n         [0.6273751 , 0.63521826, 0.63126636],\n         [0.6179138 , 0.6257569 , 0.6180205 ],\n         [0.60845244, 0.6162956 , 0.60477453]],\n\n        ...,\n\n        [[0.55871516, 0.5482166 , 0.5347226 ],\n         [0.54357696, 0.5387552 , 0.523369  ],\n         [0.5475453 , 0.54362375, 0.5279375 ],\n         ...,\n         [0.5857413 , 0.58680785, 0.5714824 ],\n         [0.57100755, 0.56922644, 0.56102395],\n         [0.5568628 , 0.54901963, 0.5529412 ]],\n\n        [[0.5462765 , 0.54235494, 0.52666867],\n         [0.5538456 , 0.549924  , 0.53423774],\n         [0.5477589 , 0.5438373 , 0.52815104],\n         ...,\n         [0.5877014 , 0.5848477 , 0.5754027 ],\n         [0.584373  , 0.5881761 , 0.568746  ],\n         [0.5614298 , 0.555544  , 0.55555093]],\n\n        [[0.5502965 , 0.5463749 , 0.53068864],\n         [0.53515834, 0.53123677, 0.5155505 ],\n         [0.52754146, 0.52225244, 0.5058824 ],\n         ...,\n         [0.5768261 , 0.57433075, 0.5664876 ],\n         [0.58633316, 0.586216  , 0.57266617],\n         [0.57515067, 0.5751451 , 0.56339145]]],\n\n\n       [[[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        ...,\n\n        [[0.2627451 , 0.24313727, 0.227451  ],\n         [0.2624982 , 0.24289036, 0.22720408],\n         [0.25764015, 0.23803233, 0.22234605],\n         ...,\n         [0.606281  , 0.61411256, 0.6071493 ],\n         [0.5752385 , 0.5752385 , 0.5673954 ],\n         [0.5886889 , 0.5886889 , 0.58098215]],\n\n        [[0.2454188 , 0.22581096, 0.21012469],\n         [0.24056077, 0.22095291, 0.20526664],\n         [0.22809128, 0.20965442, 0.19338267],\n         ...,\n         [0.5930967 , 0.5966677 , 0.5941863 ],\n         [0.5775832 , 0.577598  , 0.57565373],\n         [0.5693904 , 0.5693904 , 0.5679485 ]],\n\n        [[0.1893903 , 0.17502724, 0.15671857],\n         [0.17400652, 0.16126281, 0.14214447],\n         [0.16054372, 0.1510202 , 0.13269301],\n         ...,\n         [0.57923335, 0.57923335, 0.5741497 ],\n         [0.5798973 , 0.5798973 , 0.57897556],\n         [0.5688231 , 0.5688231 , 0.561959  ]]],\n\n\n       ...,\n\n\n       [[[0.64720964, 0.6390931 , 0.61717576],\n         [0.6291522 , 0.60873026, 0.5667028 ],\n         [0.54421103, 0.50418735, 0.446914  ],\n         ...,\n         [0.6616009 , 0.6616009 , 0.669444  ],\n         [0.6379089 , 0.6379089 , 0.645752  ],\n         [0.6442394 , 0.6420949 , 0.65637153]],\n\n        [[0.604105  , 0.604105  , 0.61194813],\n         [0.6358349 , 0.6298511 , 0.6157539 ],\n         [0.6568783 , 0.6428547 , 0.60580367],\n         ...,\n         [0.64469045, 0.64469045, 0.6525336 ],\n         [0.63915324, 0.6378564 , 0.6495899 ],\n         [0.65355515, 0.6499703 , 0.668568  ]],\n\n        [[0.6069939 , 0.6069939 , 0.61483705],\n         [0.60481596, 0.60481596, 0.6126591 ],\n         [0.62446004, 0.6206091 , 0.614332  ],\n         ...,\n         [0.63406706, 0.63361794, 0.6428084 ],\n         [0.65183604, 0.6484255 , 0.6665004 ],\n         [0.64509994, 0.64362884, 0.65588516]],\n\n        ...,\n\n        [[0.6468055 , 0.6507271 , 0.65857023],\n         [0.63495946, 0.638881  , 0.64672416],\n         [0.6334374 , 0.63735896, 0.6452021 ],\n         ...,\n         [0.6115359 , 0.61534315, 0.6231863 ],\n         [0.60718   , 0.60880923, 0.61665237],\n         [0.6061168 , 0.6061168 , 0.6139599 ]],\n\n        [[0.63835025, 0.6422718 , 0.65011495],\n         [0.6325897 , 0.63651127, 0.6443544 ],\n         [0.63606524, 0.6399868 , 0.64782995],\n         ...,\n         [0.6200883 , 0.62400985, 0.631853  ],\n         [0.61355436, 0.6174759 , 0.62531906],\n         [0.60860187, 0.61094195, 0.6187851 ]],\n\n        [[0.63174194, 0.6356635 , 0.64350665],\n         [0.6347035 , 0.6386251 , 0.6464682 ],\n         [0.64240664, 0.6463282 , 0.65417135],\n         ...,\n         [0.6165621 , 0.6204837 , 0.62832683],\n         [0.622221  , 0.62614256, 0.63398576],\n         [0.6156871 , 0.61960864, 0.6274518 ]]],\n\n\n       [[[0.64773804, 0.6937124 , 0.7023661 ],\n         [0.6805998 , 0.7113957 , 0.70936567],\n         [0.6923581 , 0.708786  , 0.69526166],\n         ...,\n         [0.5351249 , 0.53904647, 0.55865437],\n         [0.5265592 , 0.53048074, 0.5500886 ],\n         [0.5094734 , 0.51339495, 0.5330028 ]],\n\n        [[0.6354102 , 0.6921714 , 0.70390713],\n         [0.662108  , 0.7006088 , 0.7047427 ],\n         [0.69659096, 0.7207238 , 0.71336347],\n         ...,\n         [0.50631404, 0.5102356 , 0.52984345],\n         [0.49027678, 0.49419835, 0.51380616],\n         [0.49170056, 0.49562213, 0.51523   ]],\n\n        [[0.6230823 , 0.69063044, 0.7054481 ],\n         [0.64607096, 0.693504  , 0.70257455],\n         [0.67809916, 0.7099369 , 0.70874053],\n         ...,\n         [0.49196386, 0.49588543, 0.5154933 ],\n         [0.49338767, 0.49730924, 0.51691705],\n         [0.5017496 , 0.50567114, 0.525279  ]],\n\n        ...,\n\n        [[0.44557983, 0.42989355, 0.39459944],\n         [0.45309615, 0.43740988, 0.40211576],\n         [0.4540029 , 0.4365034 , 0.4018137 ],\n         ...,\n         [0.5916848 , 0.5917206 , 0.622986  ],\n         [0.5972675 , 0.5990413 , 0.6250924 ],\n         [0.612251  , 0.6160147 , 0.63609606]],\n\n        [[0.45575145, 0.44006518, 0.40477106],\n         [0.4693951 , 0.45370883, 0.4184147 ],\n         [0.45354035, 0.43785408, 0.40255997],\n         ...,\n         [0.59961164, 0.5996894 , 0.6308287 ],\n         [0.61776626, 0.6193479 , 0.643849  ],\n         [0.6070473 , 0.6086046 , 0.6317589 ]],\n\n        [[0.45285028, 0.437164  , 0.4018699 ],\n         [0.4740296 , 0.45834333, 0.4230492 ],\n         [0.47326672, 0.45758045, 0.42228633],\n         ...,\n         [0.61106807, 0.6102909 , 0.63977414],\n         [0.6275784 , 0.62379116, 0.65506595],\n         [0.59622025, 0.5938252 , 0.6246469 ]]],\n\n\n       [[[0.5546962 , 0.5546962 , 0.54685307],\n         [0.54813915, 0.54813915, 0.540296  ],\n         [0.54861397, 0.54861397, 0.54077077],\n         ...,\n         [0.64410377, 0.6519469 , 0.64269924],\n         [0.6592606 , 0.6671037 , 0.655339  ],\n         [0.673348  , 0.68119115, 0.66942644]],\n\n        [[0.56272256, 0.56272256, 0.5548794 ],\n         [0.5561655 , 0.5561655 , 0.5483224 ],\n         [0.5496086 , 0.5496086 , 0.54176545],\n         ...,\n         [0.6402757 , 0.64811885, 0.63635415],\n         [0.6780858 , 0.68592894, 0.67416424],\n         [0.66821384, 0.676057  , 0.6642923 ]],\n\n        [[0.5686275 , 0.5693346 , 0.55937004],\n         [0.56419194, 0.56419194, 0.5563488 ],\n         [0.55763495, 0.55763495, 0.5497918 ],\n         ...,\n         [0.6591009 , 0.6669441 , 0.6551793 ],\n         [0.6733915 , 0.68123466, 0.66946995],\n         [0.6666667 , 0.6745098 , 0.6627451 ]],\n\n        ...,\n\n        [[0.52435905, 0.5206889 , 0.5048769 ],\n         [0.5306105 , 0.5237435 , 0.5078924 ],\n         [0.5557164 , 0.5450898 , 0.5316385 ],\n         ...,\n         [0.6       , 0.6179292 , 0.6072789 ],\n         [0.6       , 0.61960787, 0.6039216 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.52230513, 0.51838356, 0.5022947 ],\n         [0.5105155 , 0.50659394, 0.48706782],\n         [0.55385613, 0.5493634 , 0.531265  ],\n         ...,\n         [0.5982698 , 0.61438864, 0.6091694 ],\n         [0.6       , 0.6174394 , 0.6082585 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.5236826 , 0.519761  , 0.5019608 ],\n         [0.52711487, 0.5231933 , 0.5035854 ],\n         [0.54622304, 0.5423015 , 0.52308977],\n         ...,\n         [0.587568  , 0.6063623 , 0.5931167 ],\n         [0.5963106 , 0.6129193 , 0.6062307 ],\n         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0.]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_164476]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Step 6: Train the model\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     84\u001b[0m     train_generator,\n\u001b[1;32m     85\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     86\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[1;32m     87\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight_dict,\n\u001b[1;32m     88\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lr_scheduler]\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Step 7: Evaluate the model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m     95\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n         [0.66371846, 0.67940474, 0.67548317],\n         [0.6645063 , 0.6801926 , 0.676271  ],\n         ...,\n         [0.68771964, 0.6955628 , 0.6837981 ],\n         [0.6921863 , 0.70002943, 0.6882647 ],\n         [0.7087425 , 0.7131948 , 0.7065163 ]],\n\n        [[0.6696548 , 0.68895155, 0.6741987 ],\n         [0.66199183, 0.6787342 , 0.6716444 ],\n         [0.66182005, 0.6775063 , 0.67358476],\n         ...,\n         [0.6883113 , 0.6961544 , 0.6843897 ],\n         [0.7061592 , 0.7119031 , 0.7032871 ],\n         [0.7135745 , 0.7144795 , 0.713122  ]],\n\n        [[0.6482417 , 0.6582724 , 0.6457785 ],\n         [0.666122  , 0.68381566, 0.66876745],\n         [0.66483945, 0.68253094, 0.6725936 ],\n         ...,\n         [0.7035758 , 0.7106114 , 0.700058  ],\n         [0.7168738 , 0.7172604 , 0.71668047],\n         [0.68946654, 0.69572884, 0.6863353 ]],\n\n        ...,\n\n        [[0.4241208 , 0.39666983, 0.36648002],\n         [0.42744532, 0.39999434, 0.37645352],\n         [0.44072625, 0.41327527, 0.38310826],\n         ...,\n         [0.61628085, 0.6297491 , 0.62582755],\n         [0.6109359 , 0.6266222 , 0.62270063],\n         [0.5964689 , 0.6121552 , 0.60823363]],\n\n        [[0.42679948, 0.3993485 , 0.374516  ],\n         [0.4381429 , 0.41069192, 0.38181657],\n         [0.43068182, 0.40945858, 0.37601012],\n         ...,\n         [0.6071522 , 0.61499536, 0.6110738 ],\n         [0.6134333 , 0.62500316, 0.6210816 ],\n         [0.6166311 , 0.63231736, 0.6283958 ]],\n\n        [[0.43555957, 0.40810856, 0.38052487],\n         [0.43455684, 0.4113961 , 0.37859347],\n         [0.4212739 , 0.4055876 , 0.3702935 ],\n         ...,\n         [0.605832  , 0.6136751 , 0.60975355],\n         [0.606203  , 0.61404616, 0.6101246 ],\n         [0.6105857 , 0.6202572 , 0.61633563]]],\n\n\n       [[[0.6702271 , 0.674239  , 0.65463114],\n         [0.6569136 , 0.66425383, 0.644646  ],\n         [0.66620386, 0.67122155, 0.6516137 ],\n         ...,\n         [0.6096904 , 0.61753356, 0.6039216 ],\n         [0.61347497, 0.6213181 , 0.6039216 ],\n         [0.6180461 , 0.62588924, 0.6094278 ]],\n\n        [[0.6612392 , 0.6670306 , 0.64742273],\n         [0.66475403, 0.6701342 , 0.65052634],\n         [0.6583634 , 0.66534114, 0.6457333 ],\n         ...,\n         [0.6170946 , 0.6249377 , 0.6072075 ],\n         [0.6227714 , 0.6306145 , 0.62045336],\n         [0.6257891 , 0.63363224, 0.62904596]],\n\n        [[0.6514386 , 0.6591901 , 0.6395823 ],\n         [0.66808045, 0.6725036 , 0.65289575],\n         [0.659281  , 0.66602945, 0.6464216 ],\n         ...,\n         [0.6273751 , 0.63521826, 0.63126636],\n         [0.6179138 , 0.6257569 , 0.6180205 ],\n         [0.60845244, 0.6162956 , 0.60477453]],\n\n        ...,\n\n        [[0.55871516, 0.5482166 , 0.5347226 ],\n         [0.54357696, 0.5387552 , 0.523369  ],\n         [0.5475453 , 0.54362375, 0.5279375 ],\n         ...,\n         [0.5857413 , 0.58680785, 0.5714824 ],\n         [0.57100755, 0.56922644, 0.56102395],\n         [0.5568628 , 0.54901963, 0.5529412 ]],\n\n        [[0.5462765 , 0.54235494, 0.52666867],\n         [0.5538456 , 0.549924  , 0.53423774],\n         [0.5477589 , 0.5438373 , 0.52815104],\n         ...,\n         [0.5877014 , 0.5848477 , 0.5754027 ],\n         [0.584373  , 0.5881761 , 0.568746  ],\n         [0.5614298 , 0.555544  , 0.55555093]],\n\n        [[0.5502965 , 0.5463749 , 0.53068864],\n         [0.53515834, 0.53123677, 0.5155505 ],\n         [0.52754146, 0.52225244, 0.5058824 ],\n         ...,\n         [0.5768261 , 0.57433075, 0.5664876 ],\n         [0.58633316, 0.586216  , 0.57266617],\n         [0.57515067, 0.5751451 , 0.56339145]]],\n\n\n       [[[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        ...,\n\n        [[0.2627451 , 0.24313727, 0.227451  ],\n         [0.2624982 , 0.24289036, 0.22720408],\n         [0.25764015, 0.23803233, 0.22234605],\n         ...,\n         [0.606281  , 0.61411256, 0.6071493 ],\n         [0.5752385 , 0.5752385 , 0.5673954 ],\n         [0.5886889 , 0.5886889 , 0.58098215]],\n\n        [[0.2454188 , 0.22581096, 0.21012469],\n         [0.24056077, 0.22095291, 0.20526664],\n         [0.22809128, 0.20965442, 0.19338267],\n         ...,\n         [0.5930967 , 0.5966677 , 0.5941863 ],\n         [0.5775832 , 0.577598  , 0.57565373],\n         [0.5693904 , 0.5693904 , 0.5679485 ]],\n\n        [[0.1893903 , 0.17502724, 0.15671857],\n         [0.17400652, 0.16126281, 0.14214447],\n         [0.16054372, 0.1510202 , 0.13269301],\n         ...,\n         [0.57923335, 0.57923335, 0.5741497 ],\n         [0.5798973 , 0.5798973 , 0.57897556],\n         [0.5688231 , 0.5688231 , 0.561959  ]]],\n\n\n       ...,\n\n\n       [[[0.64720964, 0.6390931 , 0.61717576],\n         [0.6291522 , 0.60873026, 0.5667028 ],\n         [0.54421103, 0.50418735, 0.446914  ],\n         ...,\n         [0.6616009 , 0.6616009 , 0.669444  ],\n         [0.6379089 , 0.6379089 , 0.645752  ],\n         [0.6442394 , 0.6420949 , 0.65637153]],\n\n        [[0.604105  , 0.604105  , 0.61194813],\n         [0.6358349 , 0.6298511 , 0.6157539 ],\n         [0.6568783 , 0.6428547 , 0.60580367],\n         ...,\n         [0.64469045, 0.64469045, 0.6525336 ],\n         [0.63915324, 0.6378564 , 0.6495899 ],\n         [0.65355515, 0.6499703 , 0.668568  ]],\n\n        [[0.6069939 , 0.6069939 , 0.61483705],\n         [0.60481596, 0.60481596, 0.6126591 ],\n         [0.62446004, 0.6206091 , 0.614332  ],\n         ...,\n         [0.63406706, 0.63361794, 0.6428084 ],\n         [0.65183604, 0.6484255 , 0.6665004 ],\n         [0.64509994, 0.64362884, 0.65588516]],\n\n        ...,\n\n        [[0.6468055 , 0.6507271 , 0.65857023],\n         [0.63495946, 0.638881  , 0.64672416],\n         [0.6334374 , 0.63735896, 0.6452021 ],\n         ...,\n         [0.6115359 , 0.61534315, 0.6231863 ],\n         [0.60718   , 0.60880923, 0.61665237],\n         [0.6061168 , 0.6061168 , 0.6139599 ]],\n\n        [[0.63835025, 0.6422718 , 0.65011495],\n         [0.6325897 , 0.63651127, 0.6443544 ],\n         [0.63606524, 0.6399868 , 0.64782995],\n         ...,\n         [0.6200883 , 0.62400985, 0.631853  ],\n         [0.61355436, 0.6174759 , 0.62531906],\n         [0.60860187, 0.61094195, 0.6187851 ]],\n\n        [[0.63174194, 0.6356635 , 0.64350665],\n         [0.6347035 , 0.6386251 , 0.6464682 ],\n         [0.64240664, 0.6463282 , 0.65417135],\n         ...,\n         [0.6165621 , 0.6204837 , 0.62832683],\n         [0.622221  , 0.62614256, 0.63398576],\n         [0.6156871 , 0.61960864, 0.6274518 ]]],\n\n\n       [[[0.64773804, 0.6937124 , 0.7023661 ],\n         [0.6805998 , 0.7113957 , 0.70936567],\n         [0.6923581 , 0.708786  , 0.69526166],\n         ...,\n         [0.5351249 , 0.53904647, 0.55865437],\n         [0.5265592 , 0.53048074, 0.5500886 ],\n         [0.5094734 , 0.51339495, 0.5330028 ]],\n\n        [[0.6354102 , 0.6921714 , 0.70390713],\n         [0.662108  , 0.7006088 , 0.7047427 ],\n         [0.69659096, 0.7207238 , 0.71336347],\n         ...,\n         [0.50631404, 0.5102356 , 0.52984345],\n         [0.49027678, 0.49419835, 0.51380616],\n         [0.49170056, 0.49562213, 0.51523   ]],\n\n        [[0.6230823 , 0.69063044, 0.7054481 ],\n         [0.64607096, 0.693504  , 0.70257455],\n         [0.67809916, 0.7099369 , 0.70874053],\n         ...,\n         [0.49196386, 0.49588543, 0.5154933 ],\n         [0.49338767, 0.49730924, 0.51691705],\n         [0.5017496 , 0.50567114, 0.525279  ]],\n\n        ...,\n\n        [[0.44557983, 0.42989355, 0.39459944],\n         [0.45309615, 0.43740988, 0.40211576],\n         [0.4540029 , 0.4365034 , 0.4018137 ],\n         ...,\n         [0.5916848 , 0.5917206 , 0.622986  ],\n         [0.5972675 , 0.5990413 , 0.6250924 ],\n         [0.612251  , 0.6160147 , 0.63609606]],\n\n        [[0.45575145, 0.44006518, 0.40477106],\n         [0.4693951 , 0.45370883, 0.4184147 ],\n         [0.45354035, 0.43785408, 0.40255997],\n         ...,\n         [0.59961164, 0.5996894 , 0.6308287 ],\n         [0.61776626, 0.6193479 , 0.643849  ],\n         [0.6070473 , 0.6086046 , 0.6317589 ]],\n\n        [[0.45285028, 0.437164  , 0.4018699 ],\n         [0.4740296 , 0.45834333, 0.4230492 ],\n         [0.47326672, 0.45758045, 0.42228633],\n         ...,\n         [0.61106807, 0.6102909 , 0.63977414],\n         [0.6275784 , 0.62379116, 0.65506595],\n         [0.59622025, 0.5938252 , 0.6246469 ]]],\n\n\n       [[[0.5546962 , 0.5546962 , 0.54685307],\n         [0.54813915, 0.54813915, 0.540296  ],\n         [0.54861397, 0.54861397, 0.54077077],\n         ...,\n         [0.64410377, 0.6519469 , 0.64269924],\n         [0.6592606 , 0.6671037 , 0.655339  ],\n         [0.673348  , 0.68119115, 0.66942644]],\n\n        [[0.56272256, 0.56272256, 0.5548794 ],\n         [0.5561655 , 0.5561655 , 0.5483224 ],\n         [0.5496086 , 0.5496086 , 0.54176545],\n         ...,\n         [0.6402757 , 0.64811885, 0.63635415],\n         [0.6780858 , 0.68592894, 0.67416424],\n         [0.66821384, 0.676057  , 0.6642923 ]],\n\n        [[0.5686275 , 0.5693346 , 0.55937004],\n         [0.56419194, 0.56419194, 0.5563488 ],\n         [0.55763495, 0.55763495, 0.5497918 ],\n         ...,\n         [0.6591009 , 0.6669441 , 0.6551793 ],\n         [0.6733915 , 0.68123466, 0.66946995],\n         [0.6666667 , 0.6745098 , 0.6627451 ]],\n\n        ...,\n\n        [[0.52435905, 0.5206889 , 0.5048769 ],\n         [0.5306105 , 0.5237435 , 0.5078924 ],\n         [0.5557164 , 0.5450898 , 0.5316385 ],\n         ...,\n         [0.6       , 0.6179292 , 0.6072789 ],\n         [0.6       , 0.61960787, 0.6039216 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.52230513, 0.51838356, 0.5022947 ],\n         [0.5105155 , 0.50659394, 0.48706782],\n         [0.55385613, 0.5493634 , 0.531265  ],\n         ...,\n         [0.5982698 , 0.61438864, 0.6091694 ],\n         [0.6       , 0.6174394 , 0.6082585 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.5236826 , 0.519761  , 0.5019608 ],\n         [0.52711487, 0.5231933 , 0.5035854 ],\n         [0.54622304, 0.5423015 , 0.52308977],\n         ...,\n         [0.587568  , 0.6063623 , 0.5931167 ],\n         [0.5963106 , 0.6129193 , 0.6062307 ],\n         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0.]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.6591442 , 0.6749374 , 0.6706951 ],\n         [0.66371846, 0.67940474, 0.67548317],\n         [0.6645063 , 0.6801926 , 0.676271  ],\n         ...,\n         [0.68771964, 0.6955628 , 0.6837981 ],\n         [0.6921863 , 0.70002943, 0.6882647 ],\n         [0.7087425 , 0.7131948 , 0.7065163 ]],\n\n        [[0.6696548 , 0.68895155, 0.6741987 ],\n         [0.66199183, 0.6787342 , 0.6716444 ],\n         [0.66182005, 0.6775063 , 0.67358476],\n         ...,\n         [0.6883113 , 0.6961544 , 0.6843897 ],\n         [0.7061592 , 0.7119031 , 0.7032871 ],\n         [0.7135745 , 0.7144795 , 0.713122  ]],\n\n        [[0.6482417 , 0.6582724 , 0.6457785 ],\n         [0.666122  , 0.68381566, 0.66876745],\n         [0.66483945, 0.68253094, 0.6725936 ],\n         ...,\n         [0.7035758 , 0.7106114 , 0.700058  ],\n         [0.7168738 , 0.7172604 , 0.71668047],\n         [0.68946654, 0.69572884, 0.6863353 ]],\n\n        ...,\n\n        [[0.4241208 , 0.39666983, 0.36648002],\n         [0.42744532, 0.39999434, 0.37645352],\n         [0.44072625, 0.41327527, 0.38310826],\n         ...,\n         [0.61628085, 0.6297491 , 0.62582755],\n         [0.6109359 , 0.6266222 , 0.62270063],\n         [0.5964689 , 0.6121552 , 0.60823363]],\n\n        [[0.42679948, 0.3993485 , 0.374516  ],\n         [0.4381429 , 0.41069192, 0.38181657],\n         [0.43068182, 0.40945858, 0.37601012],\n         ...,\n         [0.6071522 , 0.61499536, 0.6110738 ],\n         [0.6134333 , 0.62500316, 0.6210816 ],\n         [0.6166311 , 0.63231736, 0.6283958 ]],\n\n        [[0.43555957, 0.40810856, 0.38052487],\n         [0.43455684, 0.4113961 , 0.37859347],\n         [0.4212739 , 0.4055876 , 0.3702935 ],\n         ...,\n         [0.605832  , 0.6136751 , 0.60975355],\n         [0.606203  , 0.61404616, 0.6101246 ],\n         [0.6105857 , 0.6202572 , 0.61633563]]],\n\n\n       [[[0.6702271 , 0.674239  , 0.65463114],\n         [0.6569136 , 0.66425383, 0.644646  ],\n         [0.66620386, 0.67122155, 0.6516137 ],\n         ...,\n         [0.6096904 , 0.61753356, 0.6039216 ],\n         [0.61347497, 0.6213181 , 0.6039216 ],\n         [0.6180461 , 0.62588924, 0.6094278 ]],\n\n        [[0.6612392 , 0.6670306 , 0.64742273],\n         [0.66475403, 0.6701342 , 0.65052634],\n         [0.6583634 , 0.66534114, 0.6457333 ],\n         ...,\n         [0.6170946 , 0.6249377 , 0.6072075 ],\n         [0.6227714 , 0.6306145 , 0.62045336],\n         [0.6257891 , 0.63363224, 0.62904596]],\n\n        [[0.6514386 , 0.6591901 , 0.6395823 ],\n         [0.66808045, 0.6725036 , 0.65289575],\n         [0.659281  , 0.66602945, 0.6464216 ],\n         ...,\n         [0.6273751 , 0.63521826, 0.63126636],\n         [0.6179138 , 0.6257569 , 0.6180205 ],\n         [0.60845244, 0.6162956 , 0.60477453]],\n\n        ...,\n\n        [[0.55871516, 0.5482166 , 0.5347226 ],\n         [0.54357696, 0.5387552 , 0.523369  ],\n         [0.5475453 , 0.54362375, 0.5279375 ],\n         ...,\n         [0.5857413 , 0.58680785, 0.5714824 ],\n         [0.57100755, 0.56922644, 0.56102395],\n         [0.5568628 , 0.54901963, 0.5529412 ]],\n\n        [[0.5462765 , 0.54235494, 0.52666867],\n         [0.5538456 , 0.549924  , 0.53423774],\n         [0.5477589 , 0.5438373 , 0.52815104],\n         ...,\n         [0.5877014 , 0.5848477 , 0.5754027 ],\n         [0.584373  , 0.5881761 , 0.568746  ],\n         [0.5614298 , 0.555544  , 0.55555093]],\n\n        [[0.5502965 , 0.5463749 , 0.53068864],\n         [0.53515834, 0.53123677, 0.5155505 ],\n         [0.52754146, 0.52225244, 0.5058824 ],\n         ...,\n         [0.5768261 , 0.57433075, 0.5664876 ],\n         [0.58633316, 0.586216  , 0.57266617],\n         [0.57515067, 0.5751451 , 0.56339145]]],\n\n\n       [[[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        [[0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         [0.7568628 , 0.79215693, 0.78823537],\n         ...,\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825],\n         [0.6784314 , 0.6784314 , 0.67058825]],\n\n        ...,\n\n        [[0.2627451 , 0.24313727, 0.227451  ],\n         [0.2624982 , 0.24289036, 0.22720408],\n         [0.25764015, 0.23803233, 0.22234605],\n         ...,\n         [0.606281  , 0.61411256, 0.6071493 ],\n         [0.5752385 , 0.5752385 , 0.5673954 ],\n         [0.5886889 , 0.5886889 , 0.58098215]],\n\n        [[0.2454188 , 0.22581096, 0.21012469],\n         [0.24056077, 0.22095291, 0.20526664],\n         [0.22809128, 0.20965442, 0.19338267],\n         ...,\n         [0.5930967 , 0.5966677 , 0.5941863 ],\n         [0.5775832 , 0.577598  , 0.57565373],\n         [0.5693904 , 0.5693904 , 0.5679485 ]],\n\n        [[0.1893903 , 0.17502724, 0.15671857],\n         [0.17400652, 0.16126281, 0.14214447],\n         [0.16054372, 0.1510202 , 0.13269301],\n         ...,\n         [0.57923335, 0.57923335, 0.5741497 ],\n         [0.5798973 , 0.5798973 , 0.57897556],\n         [0.5688231 , 0.5688231 , 0.561959  ]]],\n\n\n       ...,\n\n\n       [[[0.64720964, 0.6390931 , 0.61717576],\n         [0.6291522 , 0.60873026, 0.5667028 ],\n         [0.54421103, 0.50418735, 0.446914  ],\n         ...,\n         [0.6616009 , 0.6616009 , 0.669444  ],\n         [0.6379089 , 0.6379089 , 0.645752  ],\n         [0.6442394 , 0.6420949 , 0.65637153]],\n\n        [[0.604105  , 0.604105  , 0.61194813],\n         [0.6358349 , 0.6298511 , 0.6157539 ],\n         [0.6568783 , 0.6428547 , 0.60580367],\n         ...,\n         [0.64469045, 0.64469045, 0.6525336 ],\n         [0.63915324, 0.6378564 , 0.6495899 ],\n         [0.65355515, 0.6499703 , 0.668568  ]],\n\n        [[0.6069939 , 0.6069939 , 0.61483705],\n         [0.60481596, 0.60481596, 0.6126591 ],\n         [0.62446004, 0.6206091 , 0.614332  ],\n         ...,\n         [0.63406706, 0.63361794, 0.6428084 ],\n         [0.65183604, 0.6484255 , 0.6665004 ],\n         [0.64509994, 0.64362884, 0.65588516]],\n\n        ...,\n\n        [[0.6468055 , 0.6507271 , 0.65857023],\n         [0.63495946, 0.638881  , 0.64672416],\n         [0.6334374 , 0.63735896, 0.6452021 ],\n         ...,\n         [0.6115359 , 0.61534315, 0.6231863 ],\n         [0.60718   , 0.60880923, 0.61665237],\n         [0.6061168 , 0.6061168 , 0.6139599 ]],\n\n        [[0.63835025, 0.6422718 , 0.65011495],\n         [0.6325897 , 0.63651127, 0.6443544 ],\n         [0.63606524, 0.6399868 , 0.64782995],\n         ...,\n         [0.6200883 , 0.62400985, 0.631853  ],\n         [0.61355436, 0.6174759 , 0.62531906],\n         [0.60860187, 0.61094195, 0.6187851 ]],\n\n        [[0.63174194, 0.6356635 , 0.64350665],\n         [0.6347035 , 0.6386251 , 0.6464682 ],\n         [0.64240664, 0.6463282 , 0.65417135],\n         ...,\n         [0.6165621 , 0.6204837 , 0.62832683],\n         [0.622221  , 0.62614256, 0.63398576],\n         [0.6156871 , 0.61960864, 0.6274518 ]]],\n\n\n       [[[0.64773804, 0.6937124 , 0.7023661 ],\n         [0.6805998 , 0.7113957 , 0.70936567],\n         [0.6923581 , 0.708786  , 0.69526166],\n         ...,\n         [0.5351249 , 0.53904647, 0.55865437],\n         [0.5265592 , 0.53048074, 0.5500886 ],\n         [0.5094734 , 0.51339495, 0.5330028 ]],\n\n        [[0.6354102 , 0.6921714 , 0.70390713],\n         [0.662108  , 0.7006088 , 0.7047427 ],\n         [0.69659096, 0.7207238 , 0.71336347],\n         ...,\n         [0.50631404, 0.5102356 , 0.52984345],\n         [0.49027678, 0.49419835, 0.51380616],\n         [0.49170056, 0.49562213, 0.51523   ]],\n\n        [[0.6230823 , 0.69063044, 0.7054481 ],\n         [0.64607096, 0.693504  , 0.70257455],\n         [0.67809916, 0.7099369 , 0.70874053],\n         ...,\n         [0.49196386, 0.49588543, 0.5154933 ],\n         [0.49338767, 0.49730924, 0.51691705],\n         [0.5017496 , 0.50567114, 0.525279  ]],\n\n        ...,\n\n        [[0.44557983, 0.42989355, 0.39459944],\n         [0.45309615, 0.43740988, 0.40211576],\n         [0.4540029 , 0.4365034 , 0.4018137 ],\n         ...,\n         [0.5916848 , 0.5917206 , 0.622986  ],\n         [0.5972675 , 0.5990413 , 0.6250924 ],\n         [0.612251  , 0.6160147 , 0.63609606]],\n\n        [[0.45575145, 0.44006518, 0.40477106],\n         [0.4693951 , 0.45370883, 0.4184147 ],\n         [0.45354035, 0.43785408, 0.40255997],\n         ...,\n         [0.59961164, 0.5996894 , 0.6308287 ],\n         [0.61776626, 0.6193479 , 0.643849  ],\n         [0.6070473 , 0.6086046 , 0.6317589 ]],\n\n        [[0.45285028, 0.437164  , 0.4018699 ],\n         [0.4740296 , 0.45834333, 0.4230492 ],\n         [0.47326672, 0.45758045, 0.42228633],\n         ...,\n         [0.61106807, 0.6102909 , 0.63977414],\n         [0.6275784 , 0.62379116, 0.65506595],\n         [0.59622025, 0.5938252 , 0.6246469 ]]],\n\n\n       [[[0.5546962 , 0.5546962 , 0.54685307],\n         [0.54813915, 0.54813915, 0.540296  ],\n         [0.54861397, 0.54861397, 0.54077077],\n         ...,\n         [0.64410377, 0.6519469 , 0.64269924],\n         [0.6592606 , 0.6671037 , 0.655339  ],\n         [0.673348  , 0.68119115, 0.66942644]],\n\n        [[0.56272256, 0.56272256, 0.5548794 ],\n         [0.5561655 , 0.5561655 , 0.5483224 ],\n         [0.5496086 , 0.5496086 , 0.54176545],\n         ...,\n         [0.6402757 , 0.64811885, 0.63635415],\n         [0.6780858 , 0.68592894, 0.67416424],\n         [0.66821384, 0.676057  , 0.6642923 ]],\n\n        [[0.5686275 , 0.5693346 , 0.55937004],\n         [0.56419194, 0.56419194, 0.5563488 ],\n         [0.55763495, 0.55763495, 0.5497918 ],\n         ...,\n         [0.6591009 , 0.6669441 , 0.6551793 ],\n         [0.6733915 , 0.68123466, 0.66946995],\n         [0.6666667 , 0.6745098 , 0.6627451 ]],\n\n        ...,\n\n        [[0.52435905, 0.5206889 , 0.5048769 ],\n         [0.5306105 , 0.5237435 , 0.5078924 ],\n         [0.5557164 , 0.5450898 , 0.5316385 ],\n         ...,\n         [0.6       , 0.6179292 , 0.6072789 ],\n         [0.6       , 0.61960787, 0.6039216 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.52230513, 0.51838356, 0.5022947 ],\n         [0.5105155 , 0.50659394, 0.48706782],\n         [0.55385613, 0.5493634 , 0.531265  ],\n         ...,\n         [0.5982698 , 0.61438864, 0.6091694 ],\n         [0.6       , 0.6174394 , 0.6082585 ],\n         [0.6       , 0.61960787, 0.6039216 ]],\n\n        [[0.5236826 , 0.519761  , 0.5019608 ],\n         [0.52711487, 0.5231933 , 0.5035854 ],\n         [0.54622304, 0.5423015 , 0.52308977],\n         ...,\n         [0.587568  , 0.6063623 , 0.5931167 ],\n         [0.5963106 , 0.6129193 , 0.6062307 ],\n         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0.]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_164476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   ...,\n",
      "         [0.5857413 , 0.58680785, 0.5714824 ],\n",
      "         [0.57100755, 0.56922644, 0.56102395],\n",
      "         [0.5568628 , 0.54901963, 0.5529412 ]],\n",
      "\n",
      "        [[0.5462765 , 0.54235494, 0.52666867],\n",
      "         [0.5538456 , 0.549924  , 0.53423774],\n",
      "         [0.5477589 , 0.5438373 , 0.52815104],\n",
      "         ...,\n",
      "         [0.5877014 , 0.5848477 , 0.5754027 ],\n",
      "         [0.584373  , 0.5881761 , 0.568746  ],\n",
      "         [0.5614298 , 0.555544  , 0.55555093]],\n",
      "\n",
      "        [[0.5502965 , 0.5463749 , 0.53068864],\n",
      "         [0.53515834, 0.53123677, 0.5155505 ],\n",
      "         [0.52754146, 0.52225244, 0.5058824 ],\n",
      "         ...,\n",
      "         [0.5768261 , 0.57433075, 0.5664876 ],\n",
      "         [0.58633316, 0.586216  , 0.57266617],\n",
      "         [0.57515067, 0.5751451 , 0.56339145]]],\n",
      "\n",
      "\n",
      "       [[[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        [[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        [[0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         [0.7568628 , 0.79215693, 0.78823537],\n",
      "         ...,\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825],\n",
      "         [0.6784314 , 0.6784314 , 0.67058825]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2627451 , 0.24313727, 0.227451  ],\n",
      "         [0.2624982 , 0.24289036, 0.22720408],\n",
      "         [0.25764015, 0.23803233, 0.22234605],\n",
      "         ...,\n",
      "         [0.606281  , 0.61411256, 0.6071493 ],\n",
      "         [0.5752385 , 0.5752385 , 0.5673954 ],\n",
      "         [0.5886889 , 0.5886889 , 0.58098215]],\n",
      "\n",
      "        [[0.2454188 , 0.22581096, 0.21012469],\n",
      "         [0.24056077, 0.22095291, 0.20526664],\n",
      "         [0.22809128, 0.20965442, 0.19338267],\n",
      "         ...,\n",
      "         [0.5930967 , 0.5966677 , 0.5941863 ],\n",
      "         [0.5775832 , 0.577598  , 0.57565373],\n",
      "         [0.5693904 , 0.5693904 , 0.5679485 ]],\n",
      "\n",
      "        [[0.1893903 , 0.17502724, 0.15671857],\n",
      "         [0.17400652, 0.16126281, 0.14214447],\n",
      "         [0.16054372, 0.1510202 , 0.13269301],\n",
      "         ...,\n",
      "         [0.57923335, 0.57923335, 0.5741497 ],\n",
      "         [0.5798973 , 0.5798973 , 0.57897556],\n",
      "         [0.5688231 , 0.5688231 , 0.561959  ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.64720964, 0.6390931 , 0.61717576],\n",
      "         [0.6291522 , 0.60873026, 0.5667028 ],\n",
      "         [0.54421103, 0.50418735, 0.446914  ],\n",
      "         ...,\n",
      "         [0.6616009 , 0.6616009 , 0.669444  ],\n",
      "         [0.6379089 , 0.6379089 , 0.645752  ],\n",
      "         [0.6442394 , 0.6420949 , 0.65637153]],\n",
      "\n",
      "        [[0.604105  , 0.604105  , 0.61194813],\n",
      "         [0.6358349 , 0.6298511 , 0.6157539 ],\n",
      "         [0.6568783 , 0.6428547 , 0.60580367],\n",
      "         ...,\n",
      "         [0.64469045, 0.64469045, 0.6525336 ],\n",
      "         [0.63915324, 0.6378564 , 0.6495899 ],\n",
      "         [0.65355515, 0.6499703 , 0.668568  ]],\n",
      "\n",
      "        [[0.6069939 , 0.6069939 , 0.61483705],\n",
      "         [0.60481596, 0.60481596, 0.6126591 ],\n",
      "         [0.62446004, 0.6206091 , 0.614332  ],\n",
      "         ...,\n",
      "         [0.63406706, 0.63361794, 0.6428084 ],\n",
      "         [0.65183604, 0.6484255 , 0.6665004 ],\n",
      "         [0.64509994, 0.64362884, 0.65588516]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6468055 , 0.6507271 , 0.65857023],\n",
      "         [0.63495946, 0.638881  , 0.64672416],\n",
      "         [0.6334374 , 0.63735896, 0.6452021 ],\n",
      "         ...,\n",
      "         [0.6115359 , 0.61534315, 0.6231863 ],\n",
      "         [0.60718   , 0.60880923, 0.61665237],\n",
      "         [0.6061168 , 0.6061168 , 0.6139599 ]],\n",
      "\n",
      "        [[0.63835025, 0.6422718 , 0.65011495],\n",
      "         [0.6325897 , 0.63651127, 0.6443544 ],\n",
      "         [0.63606524, 0.6399868 , 0.64782995],\n",
      "         ...,\n",
      "         [0.6200883 , 0.62400985, 0.631853  ],\n",
      "         [0.61355436, 0.6174759 , 0.62531906],\n",
      "         [0.60860187, 0.61094195, 0.6187851 ]],\n",
      "\n",
      "        [[0.63174194, 0.6356635 , 0.64350665],\n",
      "         [0.6347035 , 0.6386251 , 0.6464682 ],\n",
      "         [0.64240664, 0.6463282 , 0.65417135],\n",
      "         ...,\n",
      "         [0.6165621 , 0.6204837 , 0.62832683],\n",
      "         [0.622221  , 0.62614256, 0.63398576],\n",
      "         [0.6156871 , 0.61960864, 0.6274518 ]]],\n",
      "\n",
      "\n",
      "       [[[0.64773804, 0.6937124 , 0.7023661 ],\n",
      "         [0.6805998 , 0.7113957 , 0.70936567],\n",
      "         [0.6923581 , 0.708786  , 0.69526166],\n",
      "         ...,\n",
      "         [0.5351249 , 0.53904647, 0.55865437],\n",
      "         [0.5265592 , 0.53048074, 0.5500886 ],\n",
      "         [0.5094734 , 0.51339495, 0.5330028 ]],\n",
      "\n",
      "        [[0.6354102 , 0.6921714 , 0.70390713],\n",
      "         [0.662108  , 0.7006088 , 0.7047427 ],\n",
      "         [0.69659096, 0.7207238 , 0.71336347],\n",
      "         ...,\n",
      "         [0.50631404, 0.5102356 , 0.52984345],\n",
      "         [0.49027678, 0.49419835, 0.51380616],\n",
      "         [0.49170056, 0.49562213, 0.51523   ]],\n",
      "\n",
      "        [[0.6230823 , 0.69063044, 0.7054481 ],\n",
      "         [0.64607096, 0.693504  , 0.70257455],\n",
      "         [0.67809916, 0.7099369 , 0.70874053],\n",
      "         ...,\n",
      "         [0.49196386, 0.49588543, 0.5154933 ],\n",
      "         [0.49338767, 0.49730924, 0.51691705],\n",
      "         [0.5017496 , 0.50567114, 0.525279  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.44557983, 0.42989355, 0.39459944],\n",
      "         [0.45309615, 0.43740988, 0.40211576],\n",
      "         [0.4540029 , 0.4365034 , 0.4018137 ],\n",
      "         ...,\n",
      "         [0.5916848 , 0.5917206 , 0.622986  ],\n",
      "         [0.5972675 , 0.5990413 , 0.6250924 ],\n",
      "         [0.612251  , 0.6160147 , 0.63609606]],\n",
      "\n",
      "        [[0.45575145, 0.44006518, 0.40477106],\n",
      "         [0.4693951 , 0.45370883, 0.4184147 ],\n",
      "         [0.45354035, 0.43785408, 0.40255997],\n",
      "         ...,\n",
      "         [0.59961164, 0.5996894 , 0.6308287 ],\n",
      "         [0.61776626, 0.6193479 , 0.643849  ],\n",
      "         [0.6070473 , 0.6086046 , 0.6317589 ]],\n",
      "\n",
      "        [[0.45285028, 0.437164  , 0.4018699 ],\n",
      "         [0.4740296 , 0.45834333, 0.4230492 ],\n",
      "         [0.47326672, 0.45758045, 0.42228633],\n",
      "         ...,\n",
      "         [0.61106807, 0.6102909 , 0.63977414],\n",
      "         [0.6275784 , 0.62379116, 0.65506595],\n",
      "         [0.59622025, 0.5938252 , 0.6246469 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5546962 , 0.5546962 , 0.54685307],\n",
      "         [0.54813915, 0.54813915, 0.540296  ],\n",
      "         [0.54861397, 0.54861397, 0.54077077],\n",
      "         ...,\n",
      "         [0.64410377, 0.6519469 , 0.64269924],\n",
      "         [0.6592606 , 0.6671037 , 0.655339  ],\n",
      "         [0.673348  , 0.68119115, 0.66942644]],\n",
      "\n",
      "        [[0.56272256, 0.56272256, 0.5548794 ],\n",
      "         [0.5561655 , 0.5561655 , 0.5483224 ],\n",
      "         [0.5496086 , 0.5496086 , 0.54176545],\n",
      "         ...,\n",
      "         [0.6402757 , 0.64811885, 0.63635415],\n",
      "         [0.6780858 , 0.68592894, 0.67416424],\n",
      "         [0.66821384, 0.676057  , 0.6642923 ]],\n",
      "\n",
      "        [[0.5686275 , 0.5693346 , 0.55937004],\n",
      "         [0.56419194, 0.56419194, 0.5563488 ],\n",
      "         [0.55763495, 0.55763495, 0.5497918 ],\n",
      "         ...,\n",
      "         [0.6591009 , 0.6669441 , 0.6551793 ],\n",
      "         [0.6733915 , 0.68123466, 0.66946995],\n",
      "         [0.6666667 , 0.6745098 , 0.6627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.52435905, 0.5206889 , 0.5048769 ],\n",
      "         [0.5306105 , 0.5237435 , 0.5078924 ],\n",
      "         [0.5557164 , 0.5450898 , 0.5316385 ],\n",
      "         ...,\n",
      "         [0.6       , 0.6179292 , 0.6072789 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ]],\n",
      "\n",
      "        [[0.52230513, 0.51838356, 0.5022947 ],\n",
      "         [0.5105155 , 0.50659394, 0.48706782],\n",
      "         [0.55385613, 0.5493634 , 0.531265  ],\n",
      "         ...,\n",
      "         [0.5982698 , 0.61438864, 0.6091694 ],\n",
      "         [0.6       , 0.6174394 , 0.6082585 ],\n",
      "         [0.6       , 0.61960787, 0.6039216 ]],\n",
      "\n",
      "        [[0.5236826 , 0.519761  , 0.5019608 ],\n",
      "         [0.52711487, 0.5231933 , 0.5035854 ],\n",
      "         [0.54622304, 0.5423015 , 0.52308977],\n",
      "         ...,\n",
      "         [0.587568  , 0.6063623 , 0.5931167 ],\n",
      "         [0.5963106 , 0.6129193 , 0.6062307 ],\n",
      "         [0.6       , 0.6169496 , 0.60923815]]]], dtype=float32), array([[0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.]], dtype=float32)).\n",
      "\n",
      "\n",
      "2024-11-19 21:27:22.757299: W tensorflow/core/framework/op_kernel.cc:1829] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.4504797 , 0.68577385, 0.8896954 ],\n",
      "         [0.44765   , 0.68176186, 0.88450116],\n",
      "         [0.44995156, 0.6794603 , 0.87759644],\n",
      "         ...,\n",
      "         [0.39473993, 0.5947399 , 0.8090877 ],\n",
      "         [0.38774514, 0.58774513, 0.79591507],\n",
      "         [0.37749803, 0.577498  , 0.79249936]],\n",
      "\n",
      "        [[0.45162222, 0.6819967 , 0.88755816],\n",
      "         [0.45357862, 0.6888728 , 0.8927944 ],\n",
      "         [0.4489755 , 0.68426967, 0.8881912 ],\n",
      "         ...,\n",
      "         [0.38953036, 0.5895304 , 0.79866856],\n",
      "         [0.3799308 , 0.5799308 , 0.7933103 ],\n",
      "         [0.36968368, 0.5742083 , 0.7831077 ]],\n",
      "\n",
      "        [[0.45176694, 0.67529637, 0.8831395 ],\n",
      "         [0.44852325, 0.67424923, 0.88136023],\n",
      "         [0.45312637, 0.68575704, 0.89056647],\n",
      "         ...,\n",
      "         [0.38236356, 0.58236355, 0.7941212 ],\n",
      "         [0.37211645, 0.57501924, 0.7863514 ],\n",
      "         [0.36754245, 0.57349455, 0.7802527 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.44579402, 0.68108815, 0.88500977],\n",
      "         [0.44389623, 0.6769135 , 0.881594  ],\n",
      "         [0.44579336, 0.6693227 , 0.8771659 ],\n",
      "         ...,\n",
      "         [0.26615906, 0.4465512 , 0.6491072 ],\n",
      "         [0.27766687, 0.45805904, 0.6560119 ],\n",
      "         [0.2768956 , 0.4572878 , 0.65609485]],\n",
      "\n",
      "        [[0.44318926, 0.67848337, 0.8824049 ],\n",
      "         [0.44650105, 0.6717039 , 0.8789892 ],\n",
      "         [0.43276945, 0.6562989 , 0.864142  ],\n",
      "         ...,\n",
      "         [0.25957686, 0.439969  , 0.6438906 ],\n",
      "         [0.2618784 , 0.44227058, 0.64619213],\n",
      "         [0.26991943, 0.4503116 , 0.65136343]],\n",
      "\n",
      "        [[0.4456901 , 0.6733258 , 0.87980014],\n",
      "         [0.43682402, 0.6603535 , 0.8681966 ],\n",
      "         [0.4320743 , 0.66330916, 0.8680702 ],\n",
      "         ...,\n",
      "         [0.2619213 , 0.44231346, 0.646235  ],\n",
      "         [0.2596197 , 0.4400119 , 0.6439334 ],\n",
      "         [0.26032892, 0.4407211 , 0.6446427 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20790896, 0.27264774, 0.37268066],\n",
      "         [0.2045743 , 0.26764575, 0.36601135],\n",
      "         [0.20392159, 0.26130283, 0.36068302],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        [[0.22206466, 0.2887313 , 0.3932671 ],\n",
      "         [0.21100506, 0.2772919 , 0.37887284],\n",
      "         [0.2076704 , 0.2722899 , 0.37220356],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        [[0.24604376, 0.31271043, 0.42135176],\n",
      "         [0.23444904, 0.30111572, 0.40874758],\n",
      "         [0.22111046, 0.28777713, 0.39207435],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5281262 , 0.66930264, 0.80263597],\n",
      "         [0.5269138 , 0.66809034, 0.80142367],\n",
      "         [0.5214307 , 0.6682825 , 0.7997241 ],\n",
      "         ...,\n",
      "         [0.6268725 , 0.740598  , 0.8582451 ],\n",
      "         [0.62520516, 0.73893064, 0.85657775],\n",
      "         [0.62353784, 0.7372633 , 0.8549104 ]],\n",
      "\n",
      "        [[0.5306871 , 0.67186356, 0.8051969 ],\n",
      "         [0.52179205, 0.6629685 , 0.79630184],\n",
      "         [0.5239916 , 0.67468476, 0.80484587],\n",
      "         ...,\n",
      "         [0.627451  , 0.73590285, 0.8535499 ],\n",
      "         [0.627451  , 0.7392375 , 0.8568846 ],\n",
      "         [0.6267532 , 0.7404787 , 0.85812575]],\n",
      "\n",
      "        [[0.53324795, 0.67442447, 0.8077578 ],\n",
      "         [0.5181355 , 0.6600446 , 0.7931338 ],\n",
      "         [0.52814585, 0.67949367, 0.80943656],\n",
      "         ...,\n",
      "         [0.62358975, 0.73333335, 0.85098046],\n",
      "         [0.6269244 , 0.73333335, 0.85098046],\n",
      "         [0.627451  , 0.7361414 , 0.8537885 ]]],\n",
      "\n",
      "\n",
      "       [[[0.32242545, 0.15827866, 0.0858494 ],\n",
      "         [0.32829735, 0.15525076, 0.08159909],\n",
      "         [0.33453122, 0.1553031 , 0.0783575 ],\n",
      "         ...,\n",
      "         [0.47770828, 0.4853459 , 0.47388947],\n",
      "         [0.46931198, 0.47715512, 0.4678171 ],\n",
      "         [0.45639458, 0.46423772, 0.45482308]],\n",
      "\n",
      "        [[0.32218367, 0.15194629, 0.08768486],\n",
      "         [0.33179697, 0.1551506 , 0.08744125],\n",
      "         [0.33784014, 0.1552115 , 0.08365767],\n",
      "         ...,\n",
      "         [0.45631257, 0.4622419 , 0.45334786],\n",
      "         [0.4531313 , 0.4598535 , 0.45182678],\n",
      "         [0.45663396, 0.46234617, 0.4546916 ]],\n",
      "\n",
      "        [[0.325244  , 0.14769454, 0.08971488],\n",
      "         [0.32585075, 0.14214759, 0.078439  ],\n",
      "         [0.33387944, 0.14292154, 0.07437513],\n",
      "         ...,\n",
      "         [0.45830408, 0.4630283 , 0.45594195],\n",
      "         [0.4603138 , 0.46531296, 0.45497027],\n",
      "         [0.47801515, 0.48095515, 0.47164202]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6072686 , 0.6073866 , 0.6152297 ],\n",
      "         [0.6129266 , 0.61313033, 0.62097347],\n",
      "         [0.6189758 , 0.61977154, 0.6276147 ],\n",
      "         ...,\n",
      "         [0.6607201 , 0.68032795, 0.6556349 ],\n",
      "         [0.68403953, 0.7036474 , 0.68011796],\n",
      "         [0.70245504, 0.7220629 , 0.6985335 ]],\n",
      "\n",
      "        [[0.6121348 , 0.6149617 , 0.6228048 ],\n",
      "         [0.6089708 , 0.6123896 , 0.62023276],\n",
      "         [0.597927  , 0.60160345, 0.6096804 ],\n",
      "         ...,\n",
      "         [0.6637328 , 0.68334067, 0.65804505],\n",
      "         [0.67500126, 0.6946091 , 0.6710797 ],\n",
      "         [0.7084806 , 0.72808844, 0.704559  ]],\n",
      "\n",
      "        [[0.6054749 , 0.60727614, 0.6151193 ],\n",
      "         [0.60005283, 0.60028225, 0.6095952 ],\n",
      "         [0.5897347 , 0.583924  , 0.6014092 ],\n",
      "         ...,\n",
      "         [0.66674554, 0.68635345, 0.6604553 ],\n",
      "         [0.66596293, 0.6855708 , 0.66204137],\n",
      "         [0.7125547 , 0.73216254, 0.7086331 ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.40979582, 0.5705801 , 0.77450174],\n",
      "         [0.41717106, 0.57795537, 0.781877  ],\n",
      "         [0.41631556, 0.578746  , 0.7793753 ],\n",
      "         ...,\n",
      "         [0.47529638, 0.64784545, 0.8354702 ],\n",
      "         [0.45645314, 0.6290022 , 0.8180567 ],\n",
      "         [0.4617172 , 0.6342662 , 0.8185799 ]],\n",
      "\n",
      "        [[0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.41420555, 0.57498986, 0.7789115 ],\n",
      "         ...,\n",
      "         [0.45519003, 0.627739  , 0.8198319 ],\n",
      "         [0.4586872 , 0.6312362 , 0.8158227 ],\n",
      "         [0.46618527, 0.6387343 , 0.823048  ]],\n",
      "\n",
      "        [[0.39855754, 0.5709489 , 0.76790625],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         ...,\n",
      "         [0.457104  , 0.6296531 , 0.8174058 ],\n",
      "         [0.46301892, 0.63556796, 0.81988174],\n",
      "         [0.4766333 , 0.6491823 , 0.8334961 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2825154 , 0.38055465, 0.541339  ],\n",
      "         [0.2786982 , 0.3877017 , 0.5448313 ],\n",
      "         [0.274881  , 0.38113454, 0.55574924],\n",
      "         ...,\n",
      "         [0.63148445, 0.75697464, 0.9099158 ],\n",
      "         [0.6296789 , 0.75516915, 0.9081103 ],\n",
      "         [0.63459575, 0.760086  , 0.91302717]],\n",
      "\n",
      "        [[0.2802814 , 0.38453534, 0.54324806],\n",
      "         [0.27646416, 0.3843009 , 0.55099976],\n",
      "         [0.28196126, 0.3878436 , 0.5643142 ],\n",
      "         ...,\n",
      "         [0.637476  , 0.7629663 , 0.91590744],\n",
      "         [0.63444996, 0.75994015, 0.9128813 ],\n",
      "         [0.6277019 , 0.75319207, 0.90613323]],\n",
      "\n",
      "        [[0.27804735, 0.38746724, 0.5462502 ],\n",
      "         [0.2756286 , 0.38151094, 0.5579815 ],\n",
      "         [0.29107276, 0.39642915, 0.5727244 ],\n",
      "         ...,\n",
      "         [0.6317678 , 0.7560724 , 0.90940875],\n",
      "         [0.63549906, 0.76098925, 0.9139304 ],\n",
      "         [0.63741547, 0.7629057 , 0.9158469 ]]],\n",
      "\n",
      "\n",
      "       [[[0.557266  , 0.8082464 , 0.9886385 ],\n",
      "         [0.55416745, 0.8051479 , 0.98554003],\n",
      "         [0.55547607, 0.8064565 , 0.985462  ],\n",
      "         ...,\n",
      "         [0.09092669, 0.2673973 , 0.42818162],\n",
      "         [0.09887449, 0.27534512, 0.43612942],\n",
      "         [0.10682229, 0.2832929 , 0.44407722]],\n",
      "\n",
      "        [[0.5605698 , 0.81155026, 0.9919424 ],\n",
      "         [0.5537926 , 0.804773  , 0.9851652 ],\n",
      "         [0.55590415, 0.8068846 , 0.98727673],\n",
      "         ...,\n",
      "         [0.10864282, 0.28511342, 0.44589776],\n",
      "         [0.11659062, 0.29306123, 0.45384553],\n",
      "         [0.12453842, 0.301009  , 0.46179333]],\n",
      "\n",
      "        [[0.56078434, 0.80867535, 0.99061227],\n",
      "         [0.5570964 , 0.80807686, 0.988469  ],\n",
      "         [0.5542522 , 0.80523264, 0.9856248 ],\n",
      "         ...,\n",
      "         [0.12635896, 0.30282953, 0.46361387],\n",
      "         [0.12941177, 0.30588236, 0.46764567],\n",
      "         [0.12941177, 0.30588236, 0.46923527]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.36862746, 0.6313726 , 0.7960785 ],\n",
      "         [0.36862746, 0.6313726 , 0.7960785 ],\n",
      "         [0.3648304 , 0.62757546, 0.7922814 ],\n",
      "         ...,\n",
      "         [0.05893484, 0.15305248, 0.28638583],\n",
      "         [0.06799827, 0.15948935, 0.29282266],\n",
      "         [0.05802631, 0.14822239, 0.27736843]],\n",
      "\n",
      "        [[0.36191756, 0.6246627 , 0.78936857],\n",
      "         [0.34920105, 0.61194617, 0.77665204],\n",
      "         [0.3375438 , 0.6003852 , 0.7648022 ],\n",
      "         ...,\n",
      "         [0.05067511, 0.14479275, 0.2781261 ],\n",
      "         [0.06469438, 0.15783739, 0.29117075],\n",
      "         [0.06793799, 0.15813407, 0.290584  ]],\n",
      "\n",
      "        [[0.3386361 , 0.6018416 , 0.76516634],\n",
      "         [0.34340477, 0.6081999 , 0.7667559 ],\n",
      "         [0.34817347, 0.6145581 , 0.7683454 ],\n",
      "         ...,\n",
      "         [0.04443664, 0.1385543 , 0.27188763],\n",
      "         [0.05935857, 0.15347621, 0.28680956],\n",
      "         [0.06816777, 0.15957409, 0.29290745]]],\n",
      "\n",
      "\n",
      "       [[[0.5294118 , 0.7254902 , 0.81568635],\n",
      "         [0.5294118 , 0.7254902 , 0.81568635],\n",
      "         [0.5294118 , 0.7254902 , 0.81568635],\n",
      "         ...,\n",
      "         [0.56302303, 0.75910145, 0.8593794 ],\n",
      "         [0.55817354, 0.75425196, 0.86013436],\n",
      "         [0.5561164 , 0.74659234, 0.8506073 ]],\n",
      "\n",
      "        [[0.5258844 , 0.7290177 , 0.81568635],\n",
      "         [0.52738094, 0.7275211 , 0.81568635],\n",
      "         [0.52887756, 0.72602445, 0.81568635],\n",
      "         ...,\n",
      "         [0.56599116, 0.76206964, 0.86531574],\n",
      "         [0.5477849 , 0.7438634 , 0.84974575],\n",
      "         [0.56798905, 0.7540128 , 0.8565436 ]],\n",
      "\n",
      "        [[0.5139667 , 0.7102059 , 0.8003216 ],\n",
      "         [0.5184564 , 0.71768874, 0.8063079 ],\n",
      "         [0.5229461 , 0.7251717 , 0.8122942 ],\n",
      "         ...,\n",
      "         [0.56746584, 0.76354426, 0.86942667],\n",
      "         [0.54549664, 0.739955  , 0.8452974 ],\n",
      "         [0.5688927 , 0.7541205 , 0.853339  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3294064 , 0.53201723, 0.65358585],\n",
      "         [0.32848045, 0.52848047, 0.6380881 ],\n",
      "         [0.34623337, 0.54623336, 0.665573  ],\n",
      "         ...,\n",
      "         [0.76239973, 0.78592914, 0.77716357],\n",
      "         [0.7636706 , 0.79134136, 0.7866043 ],\n",
      "         [0.762174  , 0.7958311 , 0.79558367]],\n",
      "\n",
      "        [[0.3256689 , 0.5256689 , 0.64652276],\n",
      "         [0.3321756 , 0.5321756 , 0.640269  ],\n",
      "         [0.34901962, 0.55180013, 0.67058825],\n",
      "         ...,\n",
      "         [0.7474231 , 0.7701775 , 0.7544912 ],\n",
      "         [0.7487059 , 0.77223533, 0.7579922 ],\n",
      "         [0.7561888 , 0.7797182 , 0.7684682 ]],\n",
      "\n",
      "        [[0.327153  , 0.527153  , 0.64207053],\n",
      "         [0.339596  , 0.5395961 , 0.6536258 ],\n",
      "         [0.34901962, 0.55625236, 0.67058825],\n",
      "         ...,\n",
      "         [0.7481526 , 0.7644941 , 0.7498966 ],\n",
      "         [0.7556394 , 0.77565503, 0.75996876],\n",
      "         [0.75114965, 0.77266186, 0.7569756 ]]]], dtype=float32), array([[0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.]], dtype=float32)).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n",
      "    return nest_util.flatten_up_to(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n",
      "    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n",
      "    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/batch25/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[0.4504797 , 0.68577385, 0.8896954 ],\n",
      "         [0.44765   , 0.68176186, 0.88450116],\n",
      "         [0.44995156, 0.6794603 , 0.87759644],\n",
      "         ...,\n",
      "         [0.39473993, 0.5947399 , 0.8090877 ],\n",
      "         [0.38774514, 0.58774513, 0.79591507],\n",
      "         [0.37749803, 0.577498  , 0.79249936]],\n",
      "\n",
      "        [[0.45162222, 0.6819967 , 0.88755816],\n",
      "         [0.45357862, 0.6888728 , 0.8927944 ],\n",
      "         [0.4489755 , 0.68426967, 0.8881912 ],\n",
      "         ...,\n",
      "         [0.38953036, 0.5895304 , 0.79866856],\n",
      "         [0.3799308 , 0.5799308 , 0.7933103 ],\n",
      "         [0.36968368, 0.5742083 , 0.7831077 ]],\n",
      "\n",
      "        [[0.45176694, 0.67529637, 0.8831395 ],\n",
      "         [0.44852325, 0.67424923, 0.88136023],\n",
      "         [0.45312637, 0.68575704, 0.89056647],\n",
      "         ...,\n",
      "         [0.38236356, 0.58236355, 0.7941212 ],\n",
      "         [0.37211645, 0.57501924, 0.7863514 ],\n",
      "         [0.36754245, 0.57349455, 0.7802527 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.44579402, 0.68108815, 0.88500977],\n",
      "         [0.44389623, 0.6769135 , 0.881594  ],\n",
      "         [0.44579336, 0.6693227 , 0.8771659 ],\n",
      "         ...,\n",
      "         [0.26615906, 0.4465512 , 0.6491072 ],\n",
      "         [0.27766687, 0.45805904, 0.6560119 ],\n",
      "         [0.2768956 , 0.4572878 , 0.65609485]],\n",
      "\n",
      "        [[0.44318926, 0.67848337, 0.8824049 ],\n",
      "         [0.44650105, 0.6717039 , 0.8789892 ],\n",
      "         [0.43276945, 0.6562989 , 0.864142  ],\n",
      "         ...,\n",
      "         [0.25957686, 0.439969  , 0.6438906 ],\n",
      "         [0.2618784 , 0.44227058, 0.64619213],\n",
      "         [0.26991943, 0.4503116 , 0.65136343]],\n",
      "\n",
      "        [[0.4456901 , 0.6733258 , 0.87980014],\n",
      "         [0.43682402, 0.6603535 , 0.8681966 ],\n",
      "         [0.4320743 , 0.66330916, 0.8680702 ],\n",
      "         ...,\n",
      "         [0.2619213 , 0.44231346, 0.646235  ],\n",
      "         [0.2596197 , 0.4400119 , 0.6439334 ],\n",
      "         [0.26032892, 0.4407211 , 0.6446427 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20790896, 0.27264774, 0.37268066],\n",
      "         [0.2045743 , 0.26764575, 0.36601135],\n",
      "         [0.20392159, 0.26130283, 0.36068302],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        [[0.22206466, 0.2887313 , 0.3932671 ],\n",
      "         [0.21100506, 0.2772919 , 0.37887284],\n",
      "         [0.2076704 , 0.2722899 , 0.37220356],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        [[0.24604376, 0.31271043, 0.42135176],\n",
      "         [0.23444904, 0.30111572, 0.40874758],\n",
      "         [0.22111046, 0.28777713, 0.39207435],\n",
      "         ...,\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ],\n",
      "         [0.77647066, 0.8196079 , 0.8980393 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5281262 , 0.66930264, 0.80263597],\n",
      "         [0.5269138 , 0.66809034, 0.80142367],\n",
      "         [0.5214307 , 0.6682825 , 0.7997241 ],\n",
      "         ...,\n",
      "         [0.6268725 , 0.740598  , 0.8582451 ],\n",
      "         [0.62520516, 0.73893064, 0.85657775],\n",
      "         [0.62353784, 0.7372633 , 0.8549104 ]],\n",
      "\n",
      "        [[0.5306871 , 0.67186356, 0.8051969 ],\n",
      "         [0.52179205, 0.6629685 , 0.79630184],\n",
      "         [0.5239916 , 0.67468476, 0.80484587],\n",
      "         ...,\n",
      "         [0.627451  , 0.73590285, 0.8535499 ],\n",
      "         [0.627451  , 0.7392375 , 0.8568846 ],\n",
      "         [0.6267532 , 0.7404787 , 0.85812575]],\n",
      "\n",
      "        [[0.53324795, 0.67442447, 0.8077578 ],\n",
      "         [0.5181355 , 0.6600446 , 0.7931338 ],\n",
      "         [0.52814585, 0.67949367, 0.80943656],\n",
      "         ...,\n",
      "         [0.62358975, 0.73333335, 0.85098046],\n",
      "         [0.6269244 , 0.73333335, 0.85098046],\n",
      "         [0.627451  , 0.7361414 , 0.8537885 ]]],\n",
      "\n",
      "\n",
      "       [[[0.32242545, 0.15827866, 0.0858494 ],\n",
      "         [0.32829735, 0.15525076, 0.08159909],\n",
      "         [0.33453122, 0.1553031 , 0.0783575 ],\n",
      "         ...,\n",
      "         [0.47770828, 0.4853459 , 0.47388947],\n",
      "         [0.46931198, 0.47715512, 0.4678171 ],\n",
      "         [0.45639458, 0.46423772, 0.45482308]],\n",
      "\n",
      "        [[0.32218367, 0.15194629, 0.08768486],\n",
      "         [0.33179697, 0.1551506 , 0.08744125],\n",
      "         [0.33784014, 0.1552115 , 0.08365767],\n",
      "         ...,\n",
      "         [0.45631257, 0.4622419 , 0.45334786],\n",
      "         [0.4531313 , 0.4598535 , 0.45182678],\n",
      "         [0.45663396, 0.46234617, 0.4546916 ]],\n",
      "\n",
      "        [[0.325244  , 0.14769454, 0.08971488],\n",
      "         [0.32585075, 0.14214759, 0.078439  ],\n",
      "         [0.33387944, 0.14292154, 0.07437513],\n",
      "         ...,\n",
      "         [0.45830408, 0.4630283 , 0.45594195],\n",
      "         [0.4603138 , 0.46531296, 0.45497027],\n",
      "         [0.47801515, 0.48095515, 0.47164202]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6072686 , 0.6073866 , 0.6152297 ],\n",
      "         [0.6129266 , 0.61313033, 0.62097347],\n",
      "         [0.6189758 , 0.61977154, 0.6276147 ],\n",
      "         ...,\n",
      "         [0.6607201 , 0.68032795, 0.6556349 ],\n",
      "         [0.68403953, 0.7036474 , 0.68011796],\n",
      "         [0.70245504, 0.7220629 , 0.6985335 ]],\n",
      "\n",
      "        [[0.6121348 , 0.6149617 , 0.6228048 ],\n",
      "         [0.6089708 , 0.6123896 , 0.62023276],\n",
      "         [0.597927  , 0.60160345, 0.6096804 ],\n",
      "         ...,\n",
      "         [0.6637328 , 0.68334067, 0.65804505],\n",
      "         [0.67500126, 0.6946091 , 0.6710797 ],\n",
      "         [0.7084806 , 0.72808844, 0.704559  ]],\n",
      "\n",
      "        [[0.6054749 , 0.60727614, 0.6151193 ],\n",
      "         [0.60005283, 0.60028225, 0.6095952 ],\n",
      "         [0.5897347 , 0.583924  , 0.6014092 ],\n",
      "         ...,\n",
      "         [0.66674554, 0.68635345, 0.6604553 ],\n",
      "         [0.66596293, 0.6855708 , 0.66204137],\n",
      "         [0.7125547 , 0.73216254, 0.7086331 ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.40979582, 0.5705801 , 0.77450174],\n",
      "         [0.41717106, 0.57795537, 0.781877  ],\n",
      "         [0.41631556, 0.578746  , 0.7793753 ],\n",
      "         ...,\n",
      "         [0.47529638, 0.64784545, 0.8354702 ],\n",
      "         [0.45645314, 0.6290022 , 0.8180567 ],\n",
      "         [0.4617172 , 0.6342662 , 0.8185799 ]],\n",
      "\n",
      "        [[0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.41420555, 0.57498986, 0.7789115 ],\n",
      "         ...,\n",
      "         [0.45519003, 0.627739  , 0.8198319 ],\n",
      "         [0.4586872 , 0.6312362 , 0.8158227 ],\n",
      "         [0.46618527, 0.6387343 , 0.823048  ]],\n",
      "\n",
      "        [[0.39855754, 0.5709489 , 0.76790625],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         [0.40784317, 0.5686275 , 0.7725491 ],\n",
      "         ...,\n",
      "         [0.457104  , 0.6296531 , 0.8174058 ],\n",
      "         [0.46301892, 0.63556796, 0.81988174],\n",
      "         [0.4766333 , 0.6491823 , 0.8334961 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2825154 , 0.38055465, 0.541339  ],\n",
      "         [0.2786982 , 0.3877017 , 0.5448313 ],\n",
      "         [0.274881  , 0.38113454, 0.55574924],\n",
      "         ...,\n",
      "         [0.63148445, 0.75697464, 0.9099158 ],\n",
      "         [0.6296789 , 0.75516915, 0.9081103 ],\n",
      "         [0.63459575, 0.760086  , 0.91302717]],\n",
      "\n",
      "        [[0.2802814 , 0.38453534, 0.54324806],\n",
      "         [0.27646416, 0.3843009 , 0.55099976],\n",
      "         [0.28196126, 0.3878436 , 0.5643142 ],\n",
      "         ...,\n",
      "         [0.637476  , 0.7629663 , 0.91590744],\n",
      "         [0.63444996, 0.75994015, 0.9128813 ],\n",
      "         [0.6277019 , 0.75319207, 0.90613323]],\n",
      "\n",
      "        [[0.27804735, 0.38746724, 0.5462502 ],\n",
      "         [0.2756286 , 0.38151094, 0.5579815 ],\n",
      "         [0.29107276, 0.39642915, 0.5727244 ],\n",
      "         ...,\n",
      "         [0.6317678 , 0.7560724 , 0.90940875],\n",
      "         [0.63549906, 0.76098925, 0.9139304 ],\n",
      "         [0.63741547, 0.7629057 , 0.9158469 ]]],\n",
      "\n",
      "\n",
      "       [[[0.557266  , 0.8082464 , 0.9886385 ],\n",
      "         [0.55416745, 0.8051479 , 0.98554003],\n",
      "         [0.55547607, 0.8064565 , 0.985462  ],\n",
      "         ...,\n",
      "         [0.09092669, 0.2673973 , 0.42818162],\n",
      "         [0.09887449, 0.27534512, 0.43612942],\n",
      "         [0.10682229, 0.2832929 , 0.44407722]],\n",
      "\n",
      "        [[0.5605698 , 0.81155026, 0.9919424 ],\n",
      "         [0.5537926 , 0.804773  , 0.9851652 ],\n",
      "         [0.55590415, 0.8068846 , 0.98727673],\n",
      "         ...,\n",
      "         [0.10864282, 0.28511342, 0.44589776],\n",
      "         [0.11659062, 0.29306123, 0.45384553],\n",
      "         [0.12453842, 0.301009  , 0.46179333]],\n",
      "\n",
      "        [[0.56078434, 0.80867535, 0.99061227],\n",
      "         [0.5570964 , 0.80807686, 0.988469  ],\n",
      "         [0.5542522 , 0.80523264, 0.9856248 ],\n",
      "         ...,\n",
      "         [0.12635896, 0.30282953, 0.46361387],\n",
      "         [0.12941177, 0.30588236, 0.46764567],\n",
      "         [0.12941177, 0.30588236, 0.46923527]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.36862746, 0.6313726 , 0.7960785 ],\n",
      "         [0.36862746, 0.6313726 , 0.7960785 ],\n",
      "         [0.3648304 , 0.62757546, 0.7922814 ],\n",
      "         ...,\n",
      "         [0.05893484, 0.15305248, 0.28638583],\n",
      "         [0.06799827, 0.15948935, 0.29282266],\n",
      "         [0.05802631, 0.14822239, 0.27736843]],\n",
      "\n",
      "        [[0.36191756, 0.6246627 , 0.78936857],\n",
      "         [0.34920105, 0.61194617, 0.77665204],\n",
      "         [0.3375438 , 0.6003852 , 0.7648022 ],\n",
      "         ...,\n",
      "         [0.05067511, 0.14479275, 0.2781261 ],\n",
      "         [0.06469438, 0.15783739, 0.29117075],\n",
      "         [0.06793799, 0.15813407, 0.290584  ]],\n",
      "\n",
      "        [[0.3386361 , 0.6018416 , 0.76516634],\n",
      "         [0.34340477, 0.6081999 , 0.7667559 ],\n",
      "         [0.34817347, 0.6145581 , 0.7683454 ],\n",
      "         ...,\n",
      "         [0.04443664, 0.1385543 , 0.27188763],\n",
      "         [0.05935857, 0.15347621, 0.28680956],\n",
      "         [0.06816777, 0.15957409, 0.29290745]]],\n",
      "\n",
      "\n",
      "       [[[0.5294118 , 0.7254902 , 0.81568635],\n",
      "         [0.5294118 , 0.7254902 , 0.81568635],\n",
      "         [0.5294118 , 0.7254902 , 0.81568635],\n",
      "         ...,\n",
      "         [0.56302303, 0.75910145, 0.8593794 ],\n",
      "         [0.55817354, 0.75425196, 0.86013436],\n",
      "         [0.5561164 , 0.74659234, 0.8506073 ]],\n",
      "\n",
      "        [[0.5258844 , 0.7290177 , 0.81568635],\n",
      "         [0.52738094, 0.7275211 , 0.81568635],\n",
      "         [0.52887756, 0.72602445, 0.81568635],\n",
      "         ...,\n",
      "         [0.56599116, 0.76206964, 0.86531574],\n",
      "         [0.5477849 , 0.7438634 , 0.84974575],\n",
      "         [0.56798905, 0.7540128 , 0.8565436 ]],\n",
      "\n",
      "        [[0.5139667 , 0.7102059 , 0.8003216 ],\n",
      "         [0.5184564 , 0.71768874, 0.8063079 ],\n",
      "         [0.5229461 , 0.7251717 , 0.8122942 ],\n",
      "         ...,\n",
      "         [0.56746584, 0.76354426, 0.86942667],\n",
      "         [0.54549664, 0.739955  , 0.8452974 ],\n",
      "         [0.5688927 , 0.7541205 , 0.853339  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3294064 , 0.53201723, 0.65358585],\n",
      "         [0.32848045, 0.52848047, 0.6380881 ],\n",
      "         [0.34623337, 0.54623336, 0.665573  ],\n",
      "         ...,\n",
      "         [0.76239973, 0.78592914, 0.77716357],\n",
      "         [0.7636706 , 0.79134136, 0.7866043 ],\n",
      "         [0.762174  , 0.7958311 , 0.79558367]],\n",
      "\n",
      "        [[0.3256689 , 0.5256689 , 0.64652276],\n",
      "         [0.3321756 , 0.5321756 , 0.640269  ],\n",
      "         [0.34901962, 0.55180013, 0.67058825],\n",
      "         ...,\n",
      "         [0.7474231 , 0.7701775 , 0.7544912 ],\n",
      "         [0.7487059 , 0.77223533, 0.7579922 ],\n",
      "         [0.7561888 , 0.7797182 , 0.7684682 ]],\n",
      "\n",
      "        [[0.327153  , 0.527153  , 0.64207053],\n",
      "         [0.339596  , 0.5395961 , 0.6536258 ],\n",
      "         [0.34901962, 0.55625236, 0.67058825],\n",
      "         ...,\n",
      "         [0.7481526 , 0.7644941 , 0.7498966 ],\n",
      "         [0.7556394 , 0.77565503, 0.75996876],\n",
      "         [0.75114965, 0.77266186, 0.7569756 ]]]], dtype=float32), array([[0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.]], dtype=float32)).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Set up data augmentation\n",
    "train_data_path = '/home/batch25/Desktop/train_data2'\n",
    "val_data_path = '/home/batch25/Desktop/val_data2'\n",
    "test_data_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "# Step 2: Load InceptionV3 and build the model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Unfreeze the last few layers for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  # Unfreeze layers after this point\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the custom model on top of InceptionV3\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5 classes as per your dataset\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model with a low initial learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Compute class weights to address class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Step 5: Set up learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Step 6: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Step 8: Calculate precision, recall, F1 score for the whole model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get true labels and predictions\n",
    "true_labels = test_generator.classes\n",
    "predictions = np.argmax(model.predict(test_generator), axis=-1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(true_labels, predictions, target_names=test_generator.class_indices)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f79d4e-d67c-490d-a779-3e41e119c037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by model.fit()\n",
    "# It contains 'history.history' which stores metrics like loss and accuracy\n",
    "\n",
    "# Step 1: Extract loss and accuracy values from the history\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']  # Validation loss\n",
    "val_accuracy = history.history['val_accuracy']  # Validation accuracy\n",
    "\n",
    "# Step 2: Create subplots to plot the graphs side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Loss vs Epochs\n",
    "ax1.plot(loss, label='Training Loss')\n",
    "ax1.plot(val_loss, label='Validation Loss', linestyle='--')\n",
    "ax1.set_title('Loss vs Epochs')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot Accuracy vs Epochs\n",
    "ax2.plot(accuracy, label='Training Accuracy')\n",
    "ax2.plot(val_accuracy, label='Validation Accuracy', linestyle='--')\n",
    "ax2.set_title('Accuracy vs Epochs')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915256c3-664d-4ee7-9fe3-ed7051a7b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,906,085</span> (91.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,906,085\u001b[0m (91.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,871,653</span> (91.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,871,653\u001b[0m (91.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.1702 - loss: 1.9446 - val_accuracy: 0.2692 - val_loss: 2.4412 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 492ms/step - accuracy: 0.2500 - loss: 1.7724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 603ms/step - accuracy: 0.2500 - loss: 1.7724 - val_accuracy: 0.2692 - val_loss: 2.3766 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.2896 - loss: 1.6805 - val_accuracy: 0.1538 - val_loss: 2.1887 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 604ms/step - accuracy: 0.1875 - loss: 1.7706 - val_accuracy: 0.2308 - val_loss: 2.2623 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 0.3818 - loss: 1.5065 - val_accuracy: 0.3462 - val_loss: 2.2336 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597ms/step - accuracy: 0.3125 - loss: 1.6030 - val_accuracy: 0.3462 - val_loss: 2.1590 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.4275 - loss: 1.4471 - val_accuracy: 0.3077 - val_loss: 2.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 611ms/step - accuracy: 0.2812 - loss: 1.5999 - val_accuracy: 0.2692 - val_loss: 2.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 0.3917 - loss: 1.4007 - val_accuracy: 0.3462 - val_loss: 2.1900 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 578ms/step - accuracy: 0.5312 - loss: 1.2152 - val_accuracy: 0.3462 - val_loss: 2.2424 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.4760 - loss: 1.2357 - val_accuracy: 0.3077 - val_loss: 2.3643 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 623ms/step - accuracy: 0.6250 - loss: 1.0814 - val_accuracy: 0.3077 - val_loss: 2.3559 - learning_rate: 5.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.5435 - loss: 1.1706 - val_accuracy: 0.3077 - val_loss: 2.3042 - learning_rate: 5.0000e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.4333 - loss: 1.8441\n",
      "Test Accuracy: 0.4333333373069763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.17      0.22         6\n",
      "          10       0.50      0.50      0.50         6\n",
      "          12       0.43      1.00      0.60         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "           5       0.43      0.50      0.46         6\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.34      0.43      0.36        30\n",
      "weighted avg       0.34      0.43      0.36        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/batch25/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/batch25/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Paths to your datasets (update these paths accordingly)\n",
    "train_data_path = '/home/batch25/Desktop/train_data2'\n",
    "val_data_path = '/home/batch25/Desktop/val_data2'\n",
    "test_data_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Data Preprocessing with enhanced augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]  # Add brightness range\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Unfreeze the last few layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[-50:]:  # Unfreeze last 50 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Add dropout to prevent overfitting\n",
    "    layers.Dense(5, activation='softmax')  # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate for fine-tuning\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Set up callbacks for learning rate reduction and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Print classification metrics\n",
    "print(classification_report(true_labels, test_predictions, target_names=test_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2102335c-3ef1-479d-abea-f6b6a4b19c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,906,085</span> (91.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,906,085\u001b[0m (91.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,871,653</span> (91.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,871,653\u001b[0m (91.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.2791 - loss: 1.8812 - val_accuracy: 0.2308 - val_loss: 1.5444 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3438 - loss: 1.4157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 638ms/step - accuracy: 0.3438 - loss: 1.4157 - val_accuracy: 0.3462 - val_loss: 1.7426 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step - accuracy: 0.6068 - loss: 0.9932 - val_accuracy: 0.3846 - val_loss: 2.1993 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 622ms/step - accuracy: 0.5625 - loss: 0.7857 - val_accuracy: 0.3846 - val_loss: 2.5178 - learning_rate: 5.0000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5667 - loss: 1.1667\n",
      "Test Accuracy: 0.5666666626930237\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe6af016e80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe6af016e80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.67      0.62         6\n",
      "          10       1.00      0.17      0.29         6\n",
      "          12       0.80      0.67      0.73         6\n",
      "          20       1.00      0.50      0.67         6\n",
      "           5       0.36      0.83      0.50         6\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.75      0.57      0.56        30\n",
      "weighted avg       0.75      0.57      0.56        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Paths to your datasets (update these paths accordingly)\n",
    "train_data_path = '/home/batch25/Desktop/train_data2'\n",
    "val_data_path = '/home/batch25/Desktop/val_data2'\n",
    "test_data_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Data Preprocessing with enhanced augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2],  # Add brightness range\n",
    "    channel_shift_range=20.0,  # Add channel shift to augment color variations\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(224, 224),  # Increased image size for better feature extraction\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze more layers of the base model\n",
    "for layer in base_model.layers[-100:]:  # Unfreeze last 100 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')  # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model with a higher learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Set up callbacks for learning rate reduction and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,  # Fewer epochs to prevent overfitting\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Print classification metrics\n",
    "print(classification_report(true_labels, test_predictions, target_names=test_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "524b33da-ef98-44bb-93e8-f0229819cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 images belonging to 5 classes.\n",
      "Found 26 images belonging to 5 classes.\n",
      "Found 30 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,906,085</span> (91.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,906,085\u001b[0m (91.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,301</span> (8.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,103,301\u001b[0m (8.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,802,784\u001b[0m (83.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.2116 - loss: 9.7237 - val_accuracy: 0.2692 - val_loss: 8.1939 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2500 - loss: 10.8613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/batch25/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 612ms/step - accuracy: 0.2500 - loss: 10.8613 - val_accuracy: 0.3846 - val_loss: 4.8012 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.3666 - loss: 3.6304 - val_accuracy: 0.1923 - val_loss: 2.5801 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597ms/step - accuracy: 0.1562 - loss: 2.7543 - val_accuracy: 0.2308 - val_loss: 2.1124 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.3388 - loss: 1.9972 - val_accuracy: 0.4615 - val_loss: 1.4680 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600ms/step - accuracy: 0.4062 - loss: 1.8923 - val_accuracy: 0.3846 - val_loss: 1.4827 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.3545 - loss: 1.5253 - val_accuracy: 0.4615 - val_loss: 1.2031 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 605ms/step - accuracy: 0.4231 - loss: 1.4138 - val_accuracy: 0.5000 - val_loss: 1.1428 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.5922 - loss: 1.0778 - val_accuracy: 0.5769 - val_loss: 1.1743 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 612ms/step - accuracy: 0.4375 - loss: 1.3298 - val_accuracy: 0.5769 - val_loss: 1.0961 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.5800 - loss: 1.0092 - val_accuracy: 0.6538 - val_loss: 1.0917 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 607ms/step - accuracy: 0.6250 - loss: 1.0887 - val_accuracy: 0.6154 - val_loss: 1.0840 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6080 - loss: 0.9497 - val_accuracy: 0.5769 - val_loss: 1.0661 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 604ms/step - accuracy: 0.6875 - loss: 0.9699 - val_accuracy: 0.6154 - val_loss: 1.0601 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6067 - loss: 1.0042 - val_accuracy: 0.6923 - val_loss: 1.0032 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 614ms/step - accuracy: 0.5312 - loss: 0.9889 - val_accuracy: 0.6154 - val_loss: 0.9860 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6906 - loss: 0.8392 - val_accuracy: 0.6154 - val_loss: 1.0138 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 610ms/step - accuracy: 0.6875 - loss: 0.8159 - val_accuracy: 0.6538 - val_loss: 0.9821 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6775 - loss: 0.7950 - val_accuracy: 0.6538 - val_loss: 0.9653 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 603ms/step - accuracy: 0.6154 - loss: 0.9584 - val_accuracy: 0.6538 - val_loss: 0.9580 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.6294 - loss: 0.9139 - val_accuracy: 0.6538 - val_loss: 0.9745 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 585ms/step - accuracy: 0.7812 - loss: 0.6822 - val_accuracy: 0.6538 - val_loss: 0.9796 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7847 - loss: 0.6040 - val_accuracy: 0.5769 - val_loss: 0.9528 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593ms/step - accuracy: 0.6250 - loss: 0.8538 - val_accuracy: 0.5769 - val_loss: 0.9995 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.6121 - loss: 0.9173 - val_accuracy: 0.6923 - val_loss: 1.0117 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 591ms/step - accuracy: 0.8438 - loss: 0.5443 - val_accuracy: 0.6923 - val_loss: 1.0274 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - accuracy: 0.7849 - loss: 0.6560 - val_accuracy: 0.5769 - val_loss: 1.0557 - learning_rate: 5.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 601ms/step - accuracy: 0.7500 - loss: 0.7461 - val_accuracy: 0.5769 - val_loss: 1.0687 - learning_rate: 5.0000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5333 - loss: 0.8954\n",
      "Test Accuracy: 0.5333333611488342\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe68b9afd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe68b9afd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.17      0.29         6\n",
      "          10       0.44      0.67      0.53         6\n",
      "          12       0.60      0.50      0.55         6\n",
      "          20       0.67      0.67      0.67         6\n",
      "           5       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.63      0.53      0.51        30\n",
      "weighted avg       0.63      0.53      0.51        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Paths to your datasets (update these paths accordingly)\n",
    "train_data_path = '/home/batch25/Desktop/train_data2'\n",
    "val_data_path = '/home/batch25/Desktop/val_data2'\n",
    "test_data_path = '/home/batch25/Desktop/test_data2'\n",
    "\n",
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')  # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks to improve training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Ensure proper steps per epoch\n",
    "    epochs=30,  # You can adjust this number as per your data\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,  # Ensure proper validation steps\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on the test data\n",
    "test_predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Print classification metrics\n",
    "print(classification_report(true_labels, test_predictions, target_names=test_generator.class_indices.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe46dc-37fe-4189-972b-44c8f40b06e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
